[{"title":"Zookeeper学习笔记","url":"/2023/02/21/zookeeper-note/","content":"\n# Zookeeper\n\n> 观看[千锋最新Zookeeper集群教程-全网最全Zookeeper应用及原理分析课程_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1Ph411n7Ep/)进行学习。\n>\n> 部分笔记来源于网络。\n>\n> **本文使用的Zookeeper版本是3.7.1**\n\n- 分布式协调组件\n\n{% mermaid %}\ngraph LR\n\t用户 ==> Nginx\n\t--> a[服务A-1<br/>int flag=true] --> r\n\tb[服务A-2<br/>int flag=true] --> r\n\tr[分布式协调中心Zookeeper<br>Znode节点:flag=true<br>一旦节点发生改变,<br>就会通知所有监听改变自己的值-Watch机制<br>分布式锁可以让分布式服务处于无状态]\n{% endmermaid %}\n\n\n\n在分布式系统中，需要有zookeeper作为分布式协调组件，协调分布式系统中的状态\n\n- 分布式锁\n\nzk在实现分布式锁上，可以做到强一致性，关于分布式锁的相关知识，会在之后的ZAB协议中介绍\n\n- 无状态化的实现\n\n{% mermaid %}\nflowchart TD\n\t客户端 --> b\n\ta[分布式系统<br>登录系统] --保存登录信息--> z\n\tb[分布式系统<br>登录系统] --> z\n\tc[分布式系统<br>登录系统] --校验--> z\n\tsubgraph z[Zookeeper]\n\t\t登录信息\n\tend\n{% endmermaid %}\n\n\n\n## 安装和配置启动\n\n### 下载地址\n\n官网下载：[Apache ZooKeeper](https://zookeeper.apache.org/releases.html)\n\n阿里云镜像站下载：[apache-zookeeper安装包下载_开源镜像站-阿里云 (aliyun.com)](https://mirrors.aliyun.com/apache/zookeeper/)\n\n下载后解压即可。\n\n### 配置文件\n\n配置文件样例`conf/zoo_sample.cfg`如下：\n\n```properties\n# The number of milliseconds of each tick\ntickTime=2000\n# 允许follower初始化连接到leader最大时长，它表示tickTime时间倍数\n# 即initLimit*tickTime\ninitLimit=10\n# 允许follower与leader数据同步最大时长，它表示tickTime时间倍数\nsyncLimit=5\n# zookeeper数据（快照）储存的目录\n# 若无dataLogDir则日志也储存在此目录\ndataDir=/tmp/zookeeper\n# 对客户端提供的端口号\nclientPort=2181\n# 客户端的最大连接数\n#maxClientCnxns=60\n\n# 保存的快照数量\n#autopurge.snapRetainCount=3\n\n# 自动触发清除任务时间间隔，单位小时\n# 0表示关闭\n#autopurge.purgeInterval=1\n\n## Metrics Providers\n#\n# https://prometheus.io Metrics Exporter\n#metricsProvider.className=org.apache.zookeeper.metrics.prometheus.PrometheusMetricsProvider\n#metricsProvider.httpPort=7000\n#metricsProvider.exportJvmInfo=true\n\n\n```\n\n要启动必须要有一个配置文件，我们复制一份样例文件在相同目录并重命名为`zoo.cfg`，修改相关配置即可。\n\n**zookeeper默认寻找conf/zoo.cfg配置文件。**\n\n### 启动Zookeeper\n\n在bin目录下可以看到许多可执行脚本，后缀为cmd为Windows下执行的，sh为Linux下执行的。\n\n#### Windows下启动\n\n双击`zkServer.cmd`打开，不闪退则启动成功。\n\n双击`zkCli.cmd`打开客户端窗口。\n\n#### Linux下启动\n\n在bin目录下：\n\n- `./zkServer.sh start`启动Zookeeper\n- `./zkServer.sh status`查询Zookeeper状态信息\n- `./zkServer.sh stop`停止Zookeeper\n- 在后面添加配置文件路径来指定配置文件\n  - 如：`./zkServer.sh start ../conf/zoo.cfg`\n\n连接客户端：\n\n- `./zkCli.sh -server <host:port>`连接Zookeeper，没有-server默认连接localhost:2181\n\n## 内部数据模型\n\nZookeeper的数据是以**节点(Znode)**的形式构成一棵**树**储存。\n\n`/`为树的根。\n\n{% mermaid %}\nflowchart TD\n\t/ --> a --> aa\n\t/ --> b -->ba\n\ta --> ab\n\tb --> bb\n{% endmermaid %}\n\n\n\n### Znode的组成\n\nZookeeper中的Znode包含了四个部分\n\n data：保存数据\n\n acl：权限：\n\n- c：create 创建权限，允许在该节点下创建子节点\n\n- w：write 更新权限，允许更新该节点的数据\n\n- r：read 读取权限，允许读取该节点的内容以及子节点的列表信息\n\n- d：delete 删除权限，允许删除该节点的子节点信息\n\n- a：admin 管理者权限，允许对该节点进行acl权限设置\n\n  stat：描述当前znode的元数据\n\n  child：当前节点的子节点\n\n### Znode的类型\n\n1. **持久节点**：创建出的节点，在会话结束后依然存在。保存数据\n\n2. **持久序号节点**：创建出的节点，根据先后顺序，会在节点之后带上一个数值，越后执行数值越大，适用于分布式锁的应用场景-单调递增\n\n3. **临时节点**：临时节点是在会话结束后，自动被删除的，通过这个特性，zk可以实现服务注册与发现的效果。\n\n4. **临时序号节点**：跟持久序号节点相同，适用于临时的分布式锁\n\n5. **Container节点**（3.5.3版本新增）：Container容器节点，当容器中没有任何子节点，该容器节点会被zk定期删除\n\n6. **TTL节点**：可以指定节点的到期时间，到期后被zk定时删除。只能通过系统配置zookeeper.extendedTypeEnablee=true开启\n\n## 数据持久化\n\nzk的数据是运行在内存中，zk提供了两种持久化机制：\n\n- **事务日志**：zk把执行的命令以日志形式保存在dataLogDir指定的路径中的文件中\n\n- **数据快照**：zk会在一定的时间间隔内做一次内存数据快照，把时刻的内存数据保存在快照文件中\n\nzk通过两种形式的持久化，在恢复时**先恢复快照文件**中的数据到内存中，再用日志文件中的数据做增量恢复，这样恢复的速度更快。\n\n## zkCli客户端的使用\n\n### 多节点类型创建\n\n- 创建持久节点\n\n  create <path> [data] [acl]\n\n- 创建持久序号节点\n\n  create -s <path> [data] [acl]\n\n- 创建临时节点\n\n  create -e <path> [data] [acl]\n\n- 创建临时序号节点\n\n  create -e -s <path> [data] [acl]\n\n- 创建容器节点\n\n  create -c <path> [data] [acl]\n\n### 查询节点\n\n- 普通查询\n\n  - ls [-s -R] <path>\n\n    -s 详细信息\n\n    -R 当前目录和子目录中的所有信息\n\n- 查询节点相关信息\n\n  - cZxid：创建节点的事务ID\n  - mZxid：修改节点的事务ID\n  - pZxid：添加和删除子节点的事务ID\n  - ctime：节点创建的时间\n  - mtime：节点最近修改的时间\n  - cversion：子节点的version\n  - dataVersion：节点内数据的版本，每更新一次数据，版本会+1\n  - aclVersion：此节点的权限版本\n  - ephemeralOwner：如果当前节点是临时节点，该是是当前节点所有者的session id。如果节点不是临时节点，则该值为零\n  - dataLength：节点内数据的长度\n  - numChildren：该节点的子节点个数\n\n- 查询节点的内容\n\n  - get [-s] <path>\n\n    -s 详细信息\n\n### 删除节点\n\n- delete [-v] <path> 删除空节点\n  - -v 版本\n\n- deleteall <path> [-b batch size] 删除包括非空节点\n\n### 权限设置\n\n- 注册当前会话的账号和密码：\n\n  ~~~pseudocode\n  addauth digest <账号>:<密码>\n  ~~~\n\n- 创建节点并设置权限（指定该节点的用户，以及用户所拥有的权限s）\n\n  ~~~ pseudocode\n  create /<node> <data> auth:<账号>:<密码>:<权限>\n  ~~~\n\n  例：`create /test-node abcd auth:xiaowang:123456:cdwra`\n\n- 在另一个会话中必须先使用账号密码，才能拥有操作节点的权限\n\n## 使用Curator客户端\n\nCurator是Netflix公司开源的一套zookeeper客户端框架，Curator是对Zookeeper支持最好的客户端框架。Curator封装了大部分Zookeeper的功能，比如Leader选举、分布式锁等，减少了技术人员在使用Zookeeper时的底层细节开发工作。\n\n**引入依赖：**\n\n```xml\n<!-- https://mvnrepository.com/artifact/org.apache.zookeeper/zookeeper -->\n<dependency>\n    <groupId>org.apache.zookeeper</groupId>\n    <artifactId>zookeeper</artifactId>\n    <version>3.7.1</version>\n</dependency>\n        <!-- https://mvnrepository.com/artifact/org.apache.curator/curator-framework -->\n<dependency>\n    <groupId>org.apache.curator</groupId>\n    <artifactId>curator-framework</artifactId>\n    <version>5.4.0</version>\n</dependency>\n```\n\n**创建CuratorProperties**\n\n```java\n@Data\n@Component\n@ConfigurationProperties(prefix = \"curator\")\npublic class CuratorProperties {\n\n    private int retryCount;\n\n    private int elapsedTimeMs;\n\n    private String connectionString;\n\n    private int sessionTimeoutMs;\n\n    private int connectionTimeoutMs;\n\n}\n```\n\n**创建CuratorConfig配置类**\n\n```java\n@Configuration\npublic class CuratorConfig {\n\n    @Resource\n    private CuratorProperties curatorProperties;\n    \n    @Bean\n    public CuratorFramework curatorFramework() {\n        CuratorFramework client = CuratorFrameworkFactory.builder()\n                .connectString(curatorProperties.getConnectionString())\n                .connectionTimeoutMs(curatorProperties.getConnectionTimeoutMs())\n                .sessionTimeoutMs(curatorProperties.getSessionTimeoutMs())\n                .retryPolicy(new RetryNTimes(curatorProperties.getRetryCount(), curatorProperties.getElapsedTimeMs()))\n                .build();\n        client.start();\n        return client;\n    }\n}\n```\n\n**配置application.yml**\n\n```yaml\ncurator:\n  connection-string: localhost:2181\n  retry-count: 5\n  session-timeout-ms: 60000\n  connection-timeout-ms: 4000\n  elapsed-time-ms: 5000\n```\n\n## 分布式锁\n\n### 锁的种类：\n\n- 读锁（读锁共享）：大家都可以读。上锁前提：之前的锁没有写锁\n- 写锁（写锁排他）：只有得到写锁的才能写。上锁前提：之前没有任何锁\n\n### 如何上读锁\t\n\n- 创建一个临时序号节点，节点的数据是read，表示是读锁\n\n- 获取当前zk中序号比自己小的所有节点\n- 判断最小节点是否是读锁\n  - 如果不是读锁的话，则上锁失败，为最小节点设置监听。阻塞等待，zk的watch机制会当最小节点发生变化时通知当前节点，再执行第二步的流程\n  - 如果是读锁的话，则上锁成功。\n\n### 如何上写锁\n\n- 创建一个临时序号节点，节点的数据是write，表示写锁\n- 获取zk中所有的子节点\n- 判断自己是否是最小的节点：\n  - 如果是，则上写锁成功\n  - 如果不是，说明前面还有锁，则上锁失败，监听最小节点，如果最小节点有变化，则再执行第二步。\n\n### 羊群效应\n\n如果用上述的上锁方式，只要有节点发生变化，就会触发其他节点的监听事件，这样对zk的压力非常大，而羊群效应，可以调整成**链式监听**。解决这个问题。\n\n{% mermaid %}\ngraph LR\n\t/lock-node --> /read0001\n\t/lock-node --> /read0002\n\t/lock-node --> /read0003\n\t/lock-node --> /read0004\n\t\n\t/read0002 --监听-->/read0001\n\t/read0003 --监听-->/read0002\n\t/read0004 --监听-->/read0003\n{% endmermaid %}\n\n\n\n### Curator实现读写锁\n\n- 获取读锁\n\n~~~ java\n@Test\nvoid testGetReadLock()throws Exception{\n    //读写锁\n    InterProcessReadWriteLock interProcessReadWriteLock = new InterProcessReadWriteLock(client, \"/lock1\");\n    //获取读锁对象\n    InterProcessLock interProcessLock = interProcessReadWriteLock.readLock();\n    System.out.println(\"等待获取读锁对象中...\");\n    //获取锁\n    interProcessLock.acquire();\n    for(int i = 1; i <= 100; i ++){\n        Thread.sleep(3000);\n        System.out.println(i);\n    }\n    //释放锁\n    interProcessLock.release();\n    System.out.println(\"等待释放锁...\");\n}\n~~~\n\n- 获取写锁\n\n~~~ java\n@Test\nvoid testGetWriteLock()throws Exception{\n    //读写锁\n    InterProcessReadWriteLock interProcessReadWriteLock = new InterProcessReadWriteLock(client, \"/lock1\");\n    //获取写锁对象\n    InterProcessLock interProcessLock = interProcessReadWriteLock.writeLock();\n    System.out.println(\"等待获取写锁对象中...\");\n    //获取锁\n    interProcessLock.acquire();\n    for(int i = 1; i <= 100; i ++){\n        Thread.sleep(3000);\n        System.out.println(i);\n    }\n    //释放锁\n    interProcessLock.release();\n    System.out.println(\"等待释放锁...\");\n}\n~~~\n\n## watch机制\n\n### 介绍\n\n我们可以把Watch理解成是注册在特定Znode上的**触发器**。当这个Znode发生改变，也就是调用了**create**，**delete**，**setData**方法的时候，将会触发Znode上注册的对应事件，请求Watch的客户端会收到异步通知。\n\n具体交互过程如下：\n\n- 客户端调用getData方法，watch参数是true。服务端接到请求，返回节点数据，并且在对应的哈希表里插入被Watch的Znode路径，以及Watcher列表。\n\n- 当被Watch的Znode已删除，服务端会查找哈希表，找到该Znode对应的所有Watcher，异步通知客户端，并且删除哈希表中对应的key-value。\n\n### zkCli客户端使用Watch\n\n~~~ shell\ncreate /test date\nget -w /test\t一次性监听节点\nls -w /test\t\t监听目录，创建和删除子节点会收到通知。但是子节点中新增节点不会被监听到\nls -R -w /test\t监听子节点中节点的变化，但内容的变化不会收到通知\n~~~\n\n### Curator客户端使用Watch\n\n~~~ java\n@Test\npublic void addNodeListener() throws Exception{\n    NodeCache nodeCache = new NodeCache(curatorFramework,\"/curator-node\");\n    nodeCache.getListenable().addListener(new NodeCacheListener() {\n        @Override\n        public void nodeChanged() throws Exception{\n            log.info(\"{} path nodeChanged: \", \"/curator-node\");\n            printNodeData();\n        }\n    )};\n    nodeCache.start();\n    //System.in.read();\n}\n\npublic void printNodeData() throws Exception{\n    byte[] bytes = curatorFramework.getData().forPath(\"/curator-node\");\n    log.info(\"data: {}\", new String(bytes));\n}\n~~~\n\n## Zookeeper集群\n\n### 集群角色\n\nzookeeper集群中的节点有三种角色\n\n- Leader：处理集群的所有事务请求，集群中只有一个Leader\n- Follower：只能处理读请求，参与Leader选举\n- Observer：只能处理读请求，提升集群读的性能，但不能参与Leader选举\n\n{% mermaid %}\nflowchart LR\n\tc1[Client1] --> a\n\tc2[Client2] --> a\n\tc3[Client3] --> a\n\tsubgraph a[ ]\n\t\tLeader --> f1[Follower1]\n\t\tLeader --> f2[Follower2]\n\t\tLeader --> f3[Follower3]\n\t\tObserver\n\tend\n{% endmermaid %}\n\n### 集群搭建\n\n以搭建4个节点为例，搭建伪集群，其中一个节点为Observer\n\n- 创建4个节点的myid并设值\n\n  在ZK的数据储存目录/tmp/zookeeper中创建以下四个文件\n\n  ~~~ shell\n  /tmp/zookeeper/zk1# echo 1 > myid\n  /tmp/zookeeper/zk2# echo 2 > myid\n  /tmp/zookeeper/zk3# echo 3 > myid\n  /tmp/zookeeper/zk4# echo 4 > myid\n  ~~~\n\n- 编写4个zoo.cfg并修改以下选项\n\n  ~~~ properties\n  dataDir=/tmp/zookeeper/zk1\n  clientPort=2181\n  \n  #2001为集群通信端口，3001为集群选举端口，observer（观察者身份）\n  server.1=192.168.245.128:2001:3001\n  server.2=192.168.245.128:2002:3002\n  server.3=192.168.245.128:2003:3003\n  server.4=192.168.245.128:2004:3004:observer\n  ~~~\n\n  ### 3、连接Zookeeper集群\n\n  ~~~ shell\n  ./zkCli.sh -server 192.168.245.128:2181,192.168.245.128:2182,192.168.245.128:2183\n  ~~~\n\n## ZAB协议\n\n### 简介\n\nZookeeper作为非常重要的分布式协调组件，需要进行集群部署，集群中会以一主多从的形式进行部署。zookeeper为了保证数据的一致性，使用了ZAB（Zookeeper Atomic Broadcast）协议，这个协议解决了Zookeeper的崩溃恢复和主从数据同步的问题。\n\n### 集群选举Leader的过程\n\n**集群节点的状态：**\n\n- Looking：选举状态\n- Following：Follower节点（从节点）所处的状态\n- Leading：Leader节点（主节点）所处状态\n\n![leader选举过程](https://gitee.com/Wshape1/share-file/raw/master/blog/zookeeper/leader_looking.png)\n\n### 崩溃恢复时的Leader选举\n\nLeader建立完后，Leader周期性地不断向Follower发送心跳（ping命令，没有内容的socket）。当Leader崩溃后，Follower发现socket通道已关闭，于是Follower开始进入到Looking状态，重新回到上一节中的Leader选举状态，此时集群不能对外提供服务。\n\n### 主从服务器之间的数据同步\n\n![主从复制](https://gitee.com/Wshape1/share-file/raw/master/blog/zookeeper/lf_copy.png)\n\n### Zookeeper中的NIO与BIO的应用\n\n- NIO\n  - 用于被客户端连接的2181端口，使用的是NIO模式与客户端建立连接\n  - 客户端开启Watch时，也使用NIO，等待Zookeeper服务器的回调\n- BIO\n  - 集群在选举时，多个节点之间的投票通信端口，使用BIO进行通信\n\n## CAP理论\n\n### CAP理论\n\nCAP理论为：一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和区分容错性（Partition tolerance）这三项中的两项。\n\n- **—致性(Consistency)**\n\n一致性指\"all nodespsee the same data at the same time\"，即更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致。\n\n- **可用性(Availability)**\n\n可用性指\"Reads and writes always succeed\"，即服务一直可用，而且是正常响应时间。\n\n- **分区容错性(Partition tolerance)**\n\n分区容错性指\"the system continues to operate despite arbitrary message loss or failure of part of the system\"，即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性或可用性的服务。——避免单点故障，就要进行冗余部署，冗余部署相当于是服务的分区，这样的分区就具备了容错性。\n\n### BASE理论\n\n核心思想是即使无法做到强一致性(Strong Consistency，CAP的一致性就是强一致性)，但应用可以采用适合的方式达到最终一致性(Eventual Consitency) 。\n\n- **基本可用(Basically Available)**\n\n基本可用是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。\n\n电商大促时，为了应对访问量激增，部分用户可能会被引导到降级页面，服务层也可能只提供降级服务。这就是损失部分可用性的体现。\n\n- **软状态(Soft State)**\n\n软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是软状态的体现。mysql replication的异步复制也是一种体现。\n\n- **最终一致性(Eventual Consistency)**\n\n最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的—种特殊情况。\n\n### Zookeeper追求的一致性\n\nZookeeper在数据同步时，追求的并不是强一致性，而是顺序一致性（事务id的单调递增）\n","tags":["笔记","Zookeeper"],"categories":["Redis"]},{"title":"Redis学习笔记","url":"/2023/01/30/redis-note/","content":"\n# Redis\n\n学习[【尚硅谷】Redis 6 入门到精通 超详细 教程](https://www.bilibili.com/video/BV1Rv41177Af \"尚硅谷-Bilibili\") ，\n\n记录笔记。\n\n## 简介\n\n- Redis是一个开源的key-value存储系统。\n\n- 和Memcached类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set --有序集合)和hash（哈希类型）。\n\n- 这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。\n\n- 在此基础上，Redis支持各种不同方式的排序。\n\n- 与memcached一样，为了保证效率，数据都是缓存在内存中。\n\n- 区别的是Redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件。\n\n- 并且在此基础上实现了master-slave(主从)同步。\n\n## 安装Redis\n\n[Download | Redis](https://redis.io/download/)\n\n**已Redis6.2.10为例**\n\n- **检查gcc环境**`gcc --version`\n  - 安装gcc：`yum install gcc`\n\n**安装步骤：**\n\n1. 下载`redis-6.2.10.tar.gz`到/opt （其它目录也行）\n2. 执行`tar -zxvf redis-6.2.10.tar.gz`解压\n3. 进入redis-6.2.10/  `cd redis-6.2.10/`\n4. 执行编译 `make`\n   - 若出现错误：`make distclean` 清除编译结果\n   - 再次执行 `make`\n5. 执行安装 `make install` ，默认安装在/usr/local/bin/\n   - 使用`make install PREFIX=/usr/local/redis` 指定安装目录到/usr/local/redis\n\n**查看默认安装目录:**\n\n- redis-benchmark:性能测试工具,可以在自己本子运行,看看自己本子性能如何\n- redis-check-aof :修复有问题的 AOF 文件\n- redis-check-dump:修复有问题的 dump.rdb 文件\n- redis-sentinel : Redis 集群使用\n- **redis-server** : Redis服务器启动命令\n- **redis-cli**: 客户端，操作入口\n\n**前台启动：**`redis-server`\n\n**后台启动：**\n\n- 复制redis.conf到/etc/ ：`cp /opt/redis-6.2.10/redis.conf /etc/`\n- 编辑/etc/redis.conf `vim /etc/redis.conf`\n  - 修改`daemonize no`为`daemonize yes`\n- 执行`redis-server /etc/redis.conf`启动Redis\n- `redis-cli` 进入Redis后台，输入`ping`测试启动状态\n\n**使用Screen窗口进行后台运行：**\n\n- 安装Screen：`yum install screen`\n- 创建或进入一个screen：`screen -R <名称>`\n- 进入Screen后执行`redis-server`\n- `Ctrl + A + D`退出screen\n\n## 五大常用数据类型\n\n### Redis键\n\n**“键值对”**\n\n\n\n`keys *`查看当前库所有key  (匹配：keys *1)\n\n`exists <key>`判断某个key是否存在\n\n`type <key>` 查看你的key是什么类型\n\n`del <key>`    删除指定的key数据\n\n`unlink <key>`  根据value选择非阻塞删除，仅将keys从keyspace元数据中删除，真正的删除会在后续异步操作。\n\n`expire <key> <s>`  为给定的key设置过期时间（单位秒）\n\n`ttl <key>` 查看还有多少秒过期，-1表示永不过期，-2表示已过期\n\n \n\n`select <db>` 命令切换数据库\n\n- 默认16个数据库，类似数组下标从0开始，初始默认使用0号库\n\n`dbsize` 查看当前数据库的key的数量\n\n`flushdb` 清空当前库\n\n`flushall` 通杀全部库\n\n### Redis字符串\n\n#### 简介\n\n- String类型是二进制安全的。意味着Redis的string可以包含任何数据。比如jpg图片或者序列化的对象。\n\n- String类型是Redis最基本的数据类型，一个Redis中字符串value最多可以是512M\n\n#### 常用命令\n\n`set <key> <value>`添加键值对\n\n- `setnx` 当数据库中key不存在时，可以将key-value添加数据库\n- `setxx` 当数据库中key存在时，可以将key-value添加数据库，与NX参数互斥\n- `setex` key的超时秒数\n- `setpx` key的超时毫秒数，与EX互斥\n\n`get  <key>`查询对应键值\n\n`append <key> <value>` 将给定的<value> 追加到原值的末尾\n\n`strlen <key>` 获得值的长度\n\n\n\n**以下命令是具有原子性的：**\n\n- `incr <key>` 将 key 中储存的数字值增1，只能对数字值操作，如果为空，新增值为1\n\n- `decr <key>` 将 key 中储存的数字值减1，只能对数字值操作，如果为空，新增值为-1\n\n- `incrby / decrby <key> <步长>` 将 key 中储存的数字值增减。自定义步长。\n\n- `mset <key1><value1><key2><value2> ...`同时设置一个或多个 key-value对 \n\n- `mget <key1><key2><key3> ...`同时获取一个或多个 value \n\n- `msetnx <key1><value1><key2><value2> ...`同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。\n\n`getrange <key> <起始位置> <结束位置>`获得值的范围，类似java中的substring，**前包，后包**\n\n`setrange <key> <起始位置> <value>` 用 <value> 覆写<key>所储存的字符串值，从<起始位置>开始(**索引从0开始**)。\n\n`setex <key> <过期时间> <value>` 设置键值的同时，设置过期时间，单位秒。\n\n`getset <key> <value>` 以新换旧，设置了新值同时获得旧值。\n\n#### 数据结构\n\n​\tString的数据结构为简单动态字符串(Simple Dynamic String,缩写SDS)。是可以修改的字符串，**内部结构实现上类似于Java的ArrayList**，采用预分配冗余空间的方式来减少内存的频繁分配.\n\n​\t内部为当前字符串实际分配的空间capacity一般要高于实际字符串长度len。当字符串长度小于1M时，扩容都是加倍现有的空间，如果超过1M，扩容时一次只会多扩1M的空间。需要注意的是字符串最大长度为512M。\n\n### Redis列表\n\n#### 简介\n\n**“单键多值”**\n\n它的底层实际是个**双向链表**，对两端的操作性能很高，通过索引下标的操作中间的节点性能会较差。\n\n可以进行“头插”或“尾插”。\n\n{% mermaid %}\ngraph LR\n \tv1 --> v2 --> v1\n \tv2 --> v3 --> v2\n \tv3 --> v4 --> v3\n \tv4 --> v5 --> v4\n{% endmermaid %}\n\n#### 常用命令\n\n`lpush/rpush <key><value1><value2><value3> ....` 从左边/右边插入一个或多个值。\n\n`lpop/rpop <key>` 从左边/右边吐出一个值。有值才有键。\n\n \n\n`rpoplpush <key1> <key2>` 从<key1> 列表右边吐出一个值，插到<key2>列表左边。\n\n \n\n`lrange <key> <start> <stop>` 按照索引下标获得元素(从左到右)\n\n- `lrange <key> 0 -1`查看list的全部值\n\n`lindex <key> <index>`按照索引下标获得元素(从左到右)\n\n`llen <key>` 获得列表长度 \n\n \n\n`linsert <key> before <value> <newvalue>`在<value>的后面插入<newvalue>插入值\n\n`lrem <key> <n> <value>`从左边删除n个value(从左到右)\n\n`lset <key> <index> <value>` 将列表key下标为index的值替换成value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n\n#### 数据结构\n\n**”快速链表quickList“**\n\n首先在列表**元素较少**的情况下会使用一块连续的内存存储，这个结构是**ziplist**，也即是压缩列表。它将所有的元素紧挨着一起存储，分配的是一块连续的内存。\n\n当数据量比较多的时候才会改成quicklist。\n\n因为普通的链表需要的**附加指针空间太大**，会比较浪费空间。比如一个列表里存的只是int类型的数据，结构上还需要两个额外的指针prev和next。\n\n{% mermaid %}\ngraph LR\n \tv1[zipList] --> v2[zipList] --> v1\n \tv2 --> v3[zipList] --> v2\n \tv3 --> v4[zipList] --> v3\n \tv4 --> v5[zipList] --> v4\n{% endmermaid %}\n\nRedis将链表和ziplist结合起来组成了quicklist。也就是将多个ziplist使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。\n\n### Redis集合\n\n#### 简介\n\nRedis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以**自动排重**的。\n\nRedis的Set是string类型的**无序集合**。它底层其实是一个value为null的hash表，所以添加，删除，查找的**复杂度都是O(1)**。\n\n#### 常用命令\n\n- `sadd <key> <value1> <value2> ... ` 添加一或多个值到集合中，并忽略已存在的值\n\n- ``smembers <key>` 取出该集合的所有值。\n\n- `sismember <key> <value>` 判断集合是否含有某个值，是1，否0\n\n- `scard <key>` 返回该集合的元素个数。\n\n- `srem <key> <value1> <value2> ...` 删除集合中的某个元素。\n\n- `spop <key>`随机从该集合中吐出一个值。\n\n- `srandmember <key> <n>`随机从该集合中取出n个值。不会从集合中删除 。\n\n- `smove <source> <dest> <value>` 移动集合中的某个值到另一个集合\n\n- `sinter <key1> <key2>` 返回两个集合的交集元素。\n\n- `sunion <key1> <key2>`返回两个集合的并集元素。\n\n- `sdiff <key1> <key2>` 返回两个集合的**差集**元素(key1中的，不包含key2中的)\n\n#### 数据结构\n\nSet数据结构是**dict字典**，字典是用哈希表实现的。\n\nJava中HashSet的内部实现使用的是HashMap，只不过所有的value都指向同一个对象。Redis的set结构也是一样，它的内部也使用hash结构，所有的value都指向同一个内部值。\n\n### Redis哈希\n\n#### 简介\n\nRedis hash 是一个**键值对集合**。\n\nRedis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。\n\n类似Java里面的**Map<String,Object>**\n\n{% mermaid %}\nflowchart LR\n\tkey ==> sg\n\tsubgraph sg[ ]\n\t\t field1 --> value1\n\t\t field2 --> value2\n\t\t field3 --> value3\n\tend\n{% endmermaid %}\n\n#### 常用命令\n\n-  `hset <key> <field> <value>` 给<key>集合中的 <field>键赋值<value>\n\n- `hget <key1> <field>` 从<key1>集合<field>取出 value \n\n- `hmset <key1> <field1> <value1> <field2> <value2>...` 批量设置值\n\n- `hexists <key> <field>`查看哈希表中，给定域 field 是否存在。 \n\n- `hkeys <key>`列出该hash集合的所有field\n\n- `hvals <key>` 列出该hash集合的所有value\n\n- `hincrby <key> <field> <incr>`为哈希表中的域的值加上增量1（可以是负数）\n\n- `hsetnx <key> <field> <value>`将哈希表 key 中的域 field 的值设置为 value ，当且仅当域 field 不存在 \n\n#### 数据结构\n\nHash类型对应的数据结构是两种：ziplist（压缩列表），hashtable（哈希表）。当field-value长度较短且个数较少时，使用zipList，否则使用hashTable。\n\n### Redis有序集合Zset(Sorted Set)\n\n#### 简介\n\nZset拥有Set的特性。\n\nZset是有序集合，每个元素关联一个**”分数(score)“**（分数可以重复，也叫**权重**），按评分从高到低排序。\n\n#### 常用命令\n\n- `zadd <key> <score1> <value1> <score2> <value2> …` 将一或多个元素及其 score 值加入到有序集 key 当中。\n\n- `zrange <key> <start> <stop> [withscores]`  返回有序集 key 中，下标在<start><stop>之间的元素   \n  - 带withscores，可以让分数一起和值返回到结果集。\n\n- `zrangebyscore <key> <min> <max> [withscores] [limit offset count]` 返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。有序集成员按 score 值递增(从小到大)次序排列。 \n\n- `zrevrangebyscore key maxmin [withscores] [limit offset count]`  同上，改为从大到小排列。 \n\n- `zincrby <key> <incr> <value>`   为元素的score加上增量\n\n- `zrem <key> <value>` 删除该集合下，指定值的元素\n\n- `zcount <key> <min> <max>`统计该集合，分数区间内的元素个数 \n\n- `zrank <key> <value>` 返回该值在集合中的排名，从0开始。\n\n#### 数据结构\n\nZset底层使用了两个数据结构\n\n1. hash，hash的作用就是关联元素value和权重score，保障元素value的唯一性，可以通过元素value找到相应的score值。\n2. 跳跃表，跳跃表的目的在于给元素value排序，根据score的范围获取元素列表。\n\n## 配置文件\n\n```properties\n# redis.conf\n\n### INCLUDES ###\n#导入其它配置文件\n\n### NETWORK ###\n# 配置网络相关\n\n# 绑定的可访问地址，没有则任意IP\nbind 127.0.0.1\n\n# 是否只有本地可以访问\nprotected-mode yes\n\n# 访问端口\nport 6379\n\n# 设置tcp的backlog，backlog其实是一个连接队列。\n# backlog队列总和=未完成三次握手队列 + 已经完成三次握手队列\n# 在高并发环境下你需要一个高backlog值来避免慢客户端连接问题\n# 注意Linux内核会将这个值减小到/proc/sys/net/core/somaxconn的值（128），所以需要确认增大/proc/sys/net/core/somaxconn和/proc/sys/net/ipv4/tcp_max_syn_backlog（128）两个值来达到想要的效果\ntcp-backlog 511\n\n# 用户端空闲x秒后断开连接（0为不断开）\ntimeout 0\n\n# 对访问客户端的一种心跳检测，每个x秒检测一次。\n# 0为关闭检测，建议设置成60 \ntcp-keepalive 300\n\n### GENERAL ###\n# 通用设置\n\n# 守护进程\n# 是否开启后台守护\ndaemonize no\n\n# 存放pid文件的位置，每个实例会产生一个不同的pid文件\npidfile /var/run/redis_6379.pid\n\n# 日志记录级别\n# 四个级别：debug、verbose、notice、warning\nloglevel notice\n\n# 日志记录文件\nlogfile \"\"\n\n# 数据库数量\ndatabases 16\n\n### SECURITY ###\n# 安全相关设置\n\n# Redis访问密码\n# 命令行临时设置密码 config set requirepass xxxx\n# 命令行获取密码 config get requirepass\n# 登录 auth xxxx\n# 默认为不需要密码，取消注释下行并修改密码即可开启\n# requirepass foobared\n\n### CLIENTS ###\n# 最多同时连接Redis的客户端数\n# 默认为10000\n# maxclients 10000\n\n### MEMORY MANAGEMENT ###\n#内存管理相关设置\n\n# Redis可分配的最大内存\n# 建议设置！\n# maxmemory <bytes>\n\n# 内存管理策略，当内存占满时会遵循该策略进行管理\n# 策略有如下：\n# volatile-lru -> 使用LRU算法移除key，只对设置了过期时间的键\n# allkeys-lru -> 在所有集合key中，使用LRU算法移除key\n# volatile-lfu -> 使用LFU算法移除key，只对设置了过期时间的键\n# allkeys-lfu -> 在所有集合key中，使用LFU算法移除key\n# volatile-random -> 在过期集合中移除随机的key，只对设置了过期时间的键\n# allkeys-random -> 在所有集合key中，移除随机的key\n# volatile-ttl -> 移除那些TTL值最小的key，即那些最近要过期的key\n# noeviction -> 不进行移除。针对写操作，只是返回错误信息\n# LRU: 最近最少使用\n# LFU: 最不常用\n# LRU、LFU和volatile-ttl均采用近似随机化算法实现\n# maxmemory-policy noeviction\n\n# LRU, LFU和最小TTL算法不是精确的算法，而是近似的算法(为了节省内存)，所以你可以调整它的速度或精度。\n# 默认情况下，Redis将检查五个键，并选择一个最近使用最少的键，您可以使用以下配置指令更改样本大小。默认值5可以产生足够好的结果。10非常接近真实的LRU，但消耗更多的CPU。3更快，但不是很准确。\n# maxmemory-samples 5\n```\n\n其余配置选项会在下文陆续提到。\n\n## Redis发布和订阅\n\nRedis 发布订阅 (pub/sub) 是一种消息通信模式：发送者 (pub) 发送消息，订阅者 (sub) 接收消息。\n\nRedis 客户端可以订阅任意数量的频道。\n\n### 订阅和发布\n\n1. 客户端可以订阅频道如下图\n\n   {% mermaid %}\n   graph BT\n   \tch[channel1 频道]\n   \ta([客户端A]) --订阅--> ch\n   \tb([客户端B]) --订阅--> ch\n   \tc([客户端C]) --订阅--> ch\n   {% endmermaid %}\n\n   \n\n2. 当给这个频道发布消息后，消息就会发送给订阅的客户端\n\n   {% mermaid %}\n   graph TB\n   \tpb[PUBLISH channel1 hello]\n   \tpb --> ch[channel1 频道]\n   \tch --hello--> a([客户端A]) \n   \tch --hello--> b([客户端B]) \n   \tch --hello--> c([客户端C])\n   {% endmermaid %}\n\n### 发布订阅命令\n\n`subscribe <channel>` 订阅频道\n\n`publish <channel> <msg>` 发布信息，返回订阅者数量\n\n- **发布订阅过程自动创建频道**\n\n- **发布的消息没有持久化，如果在订阅的客户端收不到hello，只能收到订阅后发布的消息**\n\n## Redis新数据类型\n\n### Bitmaps\n\n#### 简介\n\nRedis提供了Bitmaps这个“数据类型”可以实现对位的操作：\n\n（1）  Bitmaps本身不是一种数据类型， 实际上它就是字符串（key-value） ， 但是它可以对字符串的位进行操作。\n\n（2）  Bitmaps单独提供了一套命令， 所以在Redis中使用Bitmaps和使用字符串的方法不太相同。 可以把Bitmaps想象成一个以位为单位的数组， 数组的每个单元只能存储0和1， 数组的下标在Bitmaps中叫做偏移量。\n\n#### 常用命令\n\n`setbit <key> <offset> <value>` 设置Bitmaps中某个偏移量的值（0或1）\n\n`getbit <key> <offset>` 获取Bitmaps中某个偏移量的值\n\n`bitcount<key> [start] [end] ` 统计字符串从start字节到end字节bit为1的数量\n\n`bitop <and|or|not|xor> <destkey> [key…]` bitop是一个复合操作， 它可以做多个Bitmaps的and（交集） 、 or（并集） 、 not（非） 、 xor（异或） 操作并将结果保存在destkey中。\n\n### HyperLogLog\n\n### 简介\n\nRedis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。\n\n在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。\n\n但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。\n\n### 常用命令\n\n`pfadd <key> <element> [element...]`  添加指定元素到 HyperLogLog 中\n\n- 如果执行命令后HLL估计的近似基数发生变化，则返回1，否则返回0。\n\n`pfcount <key> [key...]`  计算HLL的近似基数，可以计算多个HLL，比如用HLL存储每天的UV，计算一周的UV可以使用7天的UV合并计算即可\n\n`pfmerge <destkey> <sourcekey> [sourcekey...]` 将一个或多个HLL合并后的结果存储在另一个HLL中，比如每月活跃用户可以使用每天的活跃用户来合并计算可得\n\n### Geosptial\n\n#### 简介\n\nRedis 3.2 中增加了对GEO类型的支持。GEO，Geographic，地理信息的缩写。该类型，就是元素的2维坐标，在地图上就是经纬度。\n\nredis基于该类型，提供了经纬度设置，查询，范围查询，距离查询，经纬度**Hash**等常见操作。\n\n#### 常用命令\n\n`geoadd <key> <longitude> <latitude> <member> [longitude latitude member...]`  添加地理位置（经度，纬度，名称）\n\n`geopos <key> <member> [member...]` 获得指定地区的坐标值\n\n`geodist <key> <member1> <member2> [m|km|ft|mi]` 获取两个位置之间的直线距离\n\n`georadius <key> <longitude> <latitude> <radius> [m|km|ft|mi]`  以给定的经纬度为中心，找出某一半径内的元素\n\n## Jedis\n\njedis\n\n### Jedis和Lettuce比较\n\n> [Jedis和Lettuce的区别_这个名字先用着的博客-CSDN博客_jedis和lettuce](https://blog.csdn.net/weixin_38568503/article/details/124867109)\n\n## Redis整合SpringBoot\n\n### 引入依赖项\n\n```xml\n<dependency>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot-starter-data-redis</artifactId>\n</dependency>\n```\n\n注：Spring2.X集成redis所需common-pool2\n\n### 自定义配置类\n\n自定义Bean的原因是使数据能够正常序列化和反序列化存取Redis。\n\n```java\n\t@Bean\n    @SuppressWarnings(value = {\"unchecked\", \"rawtypes\"})\n    public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory factory) {\n        RedisTemplate<String, Object> template = new RedisTemplate<>();\n        template.setConnectionFactory(factory);\n\n        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);\n        ObjectMapper om = new ObjectMapper();\n        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);\n        om.activateDefaultTyping(LaissezFaireSubTypeValidator.instance, ObjectMapper.DefaultTyping.NON_FINAL);\n        jackson2JsonRedisSerializer.setObjectMapper(om);\n        \n        StringRedisSerializer stringRedisSerializer = new StringRedisSerializer();\n\t\t\n        // Key HashKey 使用StringRedisSerializer\n        template.setKeySerializer(stringRedisSerializer);\n        template.setHashKeySerializer(stringRedisSerializer);\n        \n        // Value HashValue 使用Jackson2JsonRedisSerializer\n        template.setValueSerializer(jackson2JsonRedisSerializer);\n        template.setHashValueSerializer(jackson2JsonRedisSerializer);\n        \n        template.afterPropertiesSet();\n\n        return template;\n    }\n```\n\n**注：**在**序列化**后value会多了**双引号**，但是不影响**反序列化**成String或其它类型。将Value和HashValue的Serializer设置为stringRedisSerializer可以解决双引号问题，但是将不能缓存实体类（序列化会报错）。\n\n### 配置properties\n\napplication.properties\n\n```properties\n#Redis服务器地址\nspring.redis.host=192.168.245.128\n#Redis服务器连接端口（默认为6379）\nspring.redis.port=6379\n# 账号\n#spring.redis.username=\n# 密码\n#spring.redis.password=\n#Redis数据库索引（默认为0）\nspring.redis.database= 0\n#连接超时时间（毫秒，不填则无限制）\nspring.redis.connect-timeout=1800000\n#连接池最大连接数（使用负值表示没有限制，默认为8）\nspring.redis.lettuce.pool.max-active=8\n#最大阻塞等待时间(负数表示没限制，默认为-1)\nspring.redis.lettuce.pool.max-wait=-1ms\n#连接池中的最大空闲连接（默认为8）\nspring.redis.lettuce.pool.max-idle=8\n#连接池中的最小空闲连接（默认为0）\nspring.redis.lettuce.pool.min-idle=0\n```\n\napplication.yaml\n\n```yaml\nspring:\n  redis:\n    host: 192.168.245.128\n    port: 6379\n#    username:\n#    password:\n    database: 0\n    connect-timeout: 1800000\n    lettuce:\n      pool:\n        max-active: 8\n        max-wait: -1ms\n        max-idle: 8\n        min-idle: 0\n```\n\n\n\n## 事务和锁机制\n\n### 事务的定义\n\nRedis事务是一个单独的隔离操作：事务中的所有命令都会序列化、按\t顺序地执行。**事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。**\n\nRedis事务的主要作用就是串联多个命令防止别的命令插队。\n\n### multi、exec和discard\n\n**`multi` 开启事务，进入命令组队**\n\n**`exec` 执行命令队列**\n\n**`discard`  放弃事务组队**\n\n```pseudocode\nmulti\t\t\t\texec\n |\t\t\t\t\t |\t\t\t\t\t |\n |----|----|----|----|----|----|----|----|\n |cmd1|cmd2|... |cmdx|ex 1|ex 2|... |ex x|\n |----|----|----|----|----|----|----|----|\n | \t --- Queue --->  | --- Execute --->  |\n \t\t\t\t   x|\n \t\t\t\t\t↓\n \t\t\t\tdiscard\n```\n\n### 事务的错误处理\n\n**与MySQL事务错误处理方式不同。**\n\n- 组队阶段出现错误，全部退出组队。\n- 执行阶段出现错误，其它命令正常执行。\n\n### watch和unwatch\n\n`watch <key> [key ...]`\n\n- 在执行multi之前，先执行watch可以监视一个(或多个) key ，如果在事务**执行之前这个(或这些) key** **被其他命令所改动，那么事务将被打断。**\n\n`unwatch`\n\n- 取消 watch 命令对所有 key 的监视。\n- 如果在执行 watch 命令之后，exec 命令或discard命令先被执行了的话，那么就不需要再执行unwatch了。\n\n### 乐观锁\n\n#### 简介\n\n**乐观锁(Optimistic Lock),** 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。**乐观锁适用于多读的应用类型，这样可以提高吞吐量**。Redis就是利用这种check-and-set机制实现事务的。\n\n粗略解释：我可以把东西取出来修改（但是这个东西还在），但是放回去的时候必须和取出来的时候的**版本**一致，不然就修改失败。\n\n#### 实现\n\n利用watch监听key的值变化可以打断事务组队的作用实现Redis乐观锁\n\n```java\npublic void optimisticLock() {\n    List<Object> results = redisTemplate.execute(new SessionCallback<>() {\n        @Override\n        @SuppressWarnings({\"unchecked\"})\n        public List<Object> execute(RedisOperations operations) throws DataAccessException {\n            //        开启watch监听\n            operations.watch(Arrays.asList(\"exampleKey1\", \"exampleKey2\"));\n            //        开启Redis事务\n            operations.multi();\n            //        业务逻辑\n            operations.opsForValue().increment(\"exampleKey1\");\n            operations.opsForValue().decrement(\"exampleKey2\");\n            return operations.exec();\n        }\n    });\n    if (results == null || results.size() == 0) {\n        System.out.println(\"提交事务失败\");\n        return;\n    }\n    System.out.println(\"提交事务成功\");\n}\n```\n\n### 悲观锁\n\n#### 简介\n\n**悲观锁(Pessimistic Lock)**, 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。**传统的关系型数据库里边就用到了很多这种锁机制**，比如**行锁**，**表锁**等，**读锁**，**写锁**等，都是在做操作之前先上锁。\n\n粗略解释：我把东西取出来修改（这个东西不在了），在放回去之前，其他人都不能修改这个东西。\n\n#### 实现\n\n**方式一：setnx实现**\n\n```java\npublic void pessimisticLock_setnx() {\n    boolean lock = false;\n    String uuid = UUID.randomUUID() + \":\" + Thread.currentThread().getId();\n    while (!lock) {\n        // 如果lock存在则已上锁 （lock名称自己定），set成功则返回true\n        lock = Boolean.TRUE.equals(redisTemplate.opsForValue().setIfAbsent(\"lock\", uuid, 3, TimeUnit.SECONDS));\n        if (lock) {\n            // 业务逻辑\n            redisTemplate.opsForValue().increment(\"exampleKey1\");\n            redisTemplate.opsForValue().decrement(\"exampleKey2\");\n            System.out.println(\"成功\");\n            if (uuid.equals(redisTemplate.opsForValue().get(\"lock\")))\n                redisTemplate.delete(\"lock\");\n        } else {\n            // 等待一下再发送请求\n            try {\n                Thread.sleep(10);\n            } catch (InterruptedException e) {\n                throw new RuntimeException(e);\n            }\n        }\n    }\n}\n```\n\n**方式二：Lua脚本**（推荐）\n\nRedis在2.6推出了脚本功能，允许开发者使用Lua语言编写脚本传到Redis中执行。使用脚本的好处如下:\n\n1. 减少网络开销：将复杂的或者多步的redis操作，写为一个脚本，一次提交给redis执行，减少反复连接redis的次数。提升性能。\n2. 原子操作：Redis会将整个脚本作为一个整体执行，中间不会被其他命令插入，有一定的原子性。(java等客户端则会执行多次命令完成一个业务，违反了原子性操作)。\n3. 复用：客户端发送的脚本会永久存储在Redis中，意味着其他客户端可以复用这一脚本而不需要使用代码完成同样的逻辑。\n\n```java\nprivate final String script =\n        \"\"\"\n                local exampleKey1 = KEYS[1]\n                local exampleKey2 = KEYS[2]\n                local tmpValue1 = redis.call(\"get\", exampleKey1)\n                local tmpValue2 = redis.call(\"get\", exampleKey2)\n                local incr = redis.call(\"incr\", exampleKey1)\n                local decr = redis.call(\"decr\", exampleKey2)\n                \n                if tonumber(incr) > tonumber(tmpValue1) and tonumber(decr) < tonumber(tmpValue2)\n                then\n                    return 1\n                else\n                    return 0\n                end\n                \"\"\";\npublic void pessimisticLock_lua() {\n    RedisScript<Long> redisScript = new DefaultRedisScript<>(script, Long.class);\n    Long ret = redisTemplate.execute(redisScript, Arrays.asList(\"exampleKey1\", \"exampleKey2\"));\n    if (ret != null && ret == 1) {\n        System.out.println(\"成功\");\n    } else {\n        System.out.println(\"失败\");\n    }\n}\n```\n\n### Redis事务三特性\n\n- 单独的隔离操作 \n  - 事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 \n\n- 没有隔离级别的概念 \n  - 队列中的命令没有提交之前都不会实际被执行，因为事务提交前任何指令都不会被实际执行\n\n- 不保证原子性 \n  - 事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚 \n\n## 持久化操作\n\n将Redis内存中的数据储存到硬盘。\n\n持久化方式：\n\n- RDB\n- AOF\n\n当RDB和AOF同时开启时，Redis默认使用AOF。\n\n### RDB\n\n#### 简介\n\n在指定的时间间隔内将内存中的数据集快照写入磁盘， 也就是行话讲的Snapshot快照，它恢复时是将快照文件直接读到内存里。\n\n#### 流程\n\n{% mermaid %}\ngraph LR\n\tbgsave --1--> p[父进程] --2--> fork -- 3 --> o[响应其它命令]\n    fork --> c[子进程] --4--> rdb[生成RDB文件]\n    c --5通知父进程--> p\n    p --> r([有其它子进程正在执行直接返回])\n{% endmermaid %}\n\nRedis会单独创建（fork）一个子进程来进行持久化，会先将数据写入到 一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。 整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能 如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。**RDB的缺点是最后一次持久化后的数据可能丢失**。\n\n#### 配置文件\n\n```properties\n### SNAPSHOTTING  ###\n\n# 数据库的持久化（备份）\n# save <seconds> <changes>\n# 例：'save 60 10000' 60秒内至少有10000个key发生变化则进行持久化\n# save \"\"\n\n# 当Redis无法写入磁盘的话，直接关掉Redis的写操作\nstop-writes-on-bgsave-error yes\n\n# 对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果开启，redis会采用LZF算法进行压缩。\n# 如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能。推荐yes\nrdbcompression yes\n\n# 在存储快照后，还可以让redis使用CRC64算法来进行数据校验，\n# 大约10%的性能消耗\nrdbchecksum yes\n\n# 备份文件的名称\ndbfilename dump.rdb\n\n# 备份文件的路径\n# ./表示在默认安装位置/usr/local/bin/\ndir ./\n```\n\n开启rdb备份后，在redis开启的时候会加载dump.rdb文件内容到内存中。\n\n动态停止：`redis-cli config set save \"\"`\n\n#### save和bgsave命令\n\nsave: 保存是阻塞主进程，客户端无法连接redis，等SAVE完成后，主进程才开始工作，客户端可以连接。\n\nbgsave: 是fork一个save的子进程，在执行save过程中，不影响主进程，客户端可以正常链接redis，等子进程fork执行save完成后，通知主进程，子进程关闭。\n\n> [Redis Save 与 BGSAVE 的区别 - Ray雷 - 博客园 (cnblogs.com)](https://www.cnblogs.com/rayong/p/6791330.html)\n\n#### 优缺点\n\n**优点：**\n\n- 适合大规模的数据恢复\n\n- 对数据完整性和一致性要求不高更适合使用\n\n- 节省磁盘空间\n\n- 恢复速度快\n\n**缺点：**\n\n- Fork的时候，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑\n- 虽然Redis在fork时使用了**写时拷贝技术**,但是如果数据庞大时还是比较消耗性能。\n- 在备份周期在一定间隔时间做一次备份，所以如果Redis意外down掉的话，就会丢失最后一次快照后的所有修改。\n\n### AOF\n\n#### 简介\n\n以**日志**的形式来记录每个写操作（增量保存），将Redis执行过的所有写指令记录下来(**读操作不记录**)， **只许追加文件但不可以改写文件**，redis启动之初会读取该文件重新构建数据，换言之，redis 重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。\n\n#### 流程\n\n{% mermaid %}\ngraph TD\n\twrite[命令写入] -- 1 append--> aof_buffer[AOF缓冲] \n\t-- 2 sync --> aof_file[AOF文件] -- 4 load --> reboot[重启]\n\taof_file --3 rewrite --> aof_file\n{% endmermaid %}\n\n1. 客户端的请求写命令会被append追加到AOF缓冲区内；\n2. AOF缓冲区根据AOF持久化策略[always,everysec,no]将操作sync同步到磁盘的AOF文件中；\n3. AOF文件大小超过重写策略或手动重写时，会对AOF文件rewrite重写，压缩AOF文件容量；\n4. Redis服务重启时，会重新load加载AOF文件中的写操作达到数据恢复的目的；\n\n#### 配置文件\n\n```properties\n### APPEND ONLY MODE ###\n\n# 是否开启AOF\nappendonly no\n\n# AOF文件名称\n# 默认路径在默认安装路径/usr/local/bin/\nappendfilename \"appendonly.aof\"\n\n# AOF同步频率\n# always 始终同步，，每次Redis的写入都会立刻记入日志；性能较差但数据完整性比较好\n# everysec 每秒同步，每秒记入日志一次，如果宕机，本秒的数据可能丢失。\n# no redis不主动进行同步，把同步时机交给操作系统。\nappendfsync everysec\n\n# Rewrite压缩文件\n# yes,不写入aof文件只写入aof缓存，用户请求不会阻塞，但是在这段时间如果宕机会丢失这段时间的缓存数据。（降低数据安全性，提高性能）\n# no, 会把数据写入磁盘，但是遇到重写操作，可能会发生阻塞。（数据安全，但是性能降低）\nno-appendfsync-on-rewrite no\n\n# 超过min + min * percent 时重写\nauto-aof-rewrite-percentage 100\nauto-aof-rewrite-min-size 64mb\n```\n\n#### Rewrite流程\n\n1. bgrewriteaof触发重写，判断是否当前有bgsave或bgrewriteaof在运行，如果有，则等待该命令结束后再继续执行。\n2. 主进程fork出子进程执行重写操作，保证主进程不会阻塞。\n3. 子进程遍历redis内存中数据到临时文件，客户端的写请求同时写入aof_buf缓冲区和aof_rewrite_buf重写缓冲区保证原AOF文件完整以及新AOF文件生成期间的新的数据修改动作不会丢失。\n4. 子进程写完新的AOF文件后，向主进程发信号，父进程更新统计信息。2).主进程把aof_rewrite_buf中的数据写入到新的AOF文件。\n5. 使用新的AOF文件覆盖旧的AOF文件，完成AOF重写。\n\n#### 优缺点\n\n**优点：**\n\n- 备份机制更稳健，丢失数据概率更低。\n- 可读的日志文本，通过操作AOF稳健，可以处理误操作。\n\n**缺点：**\n\n- 比起RDB占用更多的磁盘空间。\n- 恢复备份速度要慢。\n- 每次读写都同步的话，有一定的性能压力。\n- 存在个别Bug，造成恢复不能。\n\n## 主从复制\n\n### 相关内容\n\n- master主服务器，slave从服务器\n\n- 读写分离，性能扩展\n\n- 容灾快速恢复\n\n{% mermaid %}\nflowchart\n\tapp([应用]) -- 写 --> z[主]\n\tapp -- 读 --> c1[从]\n\tapp -- 读 --> c2[从]\n\tapp -- 读 --> c3[从]\n\tz -- 复制 --> c1\n\tz -- 复制 --> c2\n\tz -- 复制 --> c3\n{% endmermaid %}\n\n**注：**从服务器可以拥有自己的从服务器，且数据依次传递。\n\n**相关Redis命令：**\n\n- `info replication` 查看主从复制相关信息\n\n- `slaveof <ip> <port>` 成为某个实例的从服务器\n\n  - `slaveof no one` 自己成为主服务器\n\n  - 重启Redis失效，写入配置文件即可永久\n\n**主从读写情况：**\n\n- 服务器成为从服务器后会同步主服务器的数据\n\n- 主服务器可以读写，写入操作后会从服务器会同步\n- 从服务器只能进行读操作\n\n**主从掉线情况：**\n\n- 主服务器掉线：从服务器不变，等待主服务器上线\n- 从服务器掉线：主服务器的从服务器数量减少，从服务器上线后slaveof即可\n\n**若主服务器有设置`requirepass`则从服务器必须设置`masterauth`。**\n\n### 主从复制原理\n\n- 某服务器成为从服务器后会向主服务器发送数据同步请求（sync命令），主服务器启动后台程序将数据写入文件（RDB文件），然后文件给从服务器。（**全量复制**）\n\n- 主服务器写入操作后会发送相同命令给从服务器进行同步（**增量复制**）\n\n> [全网最清晰！Redis主从复制原理及实现，绝对给你非一般的体验 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/179266035)\n\n### 哨兵模式\n\n哨兵模式(Sentinel)，能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库。\n\n命令：`redis-sentinel <sentinel.conf>`\n\n编写sentinel.conf\n\n```properties\n# 格式sentinel monitor <哨兵监控的服务器名称> <ip> <port> <同意迁移主服务器的最小哨兵数量>\n# 例： \nsentinel monitor mymaster 127.0.0.1 6379 1 \n\n# 从服务器连主服务器的密码\nsentinel auth-pass mymaster 123456\n```\n\n当主服务器故障了，会征求其它哨兵意见认为它是否故障，之后会征求其它哨兵意见选举新的主服务器。\n\n选举新服务器条件：\n\n1. 优先级高的\n2. 偏移量最大的（拥有主服务器数据最全的）\n3. runid最小的\n\n选举之后旧主服务器会放过来成为新主服务器的从服务器。\n\n```properties\n# redis.conf\n### REPLICATION ###\n\n# 选举的优先级，值越小级别越高\nreplica-priority 100\n```\n\n> [Redis系列八：redis主从复制和哨兵 - 小不点啊 - 博客园 (cnblogs.com)](https://www.cnblogs.com/leeSmall/p/8398401.html)\n\n## 集群\n\nRedis 集群实现了对Redis的水平扩容，即启动N个redis节点，将整个数据库分布存储在这N个节点中，每个节点存储总数据的1/N。\n\nRedis 集群通过分区（partition）来提供一定程度的可用性（availability）： 即使集群中有一部分节点失效或者无法进行通讯， 集群也可以继续处理命令请求。\n\n> [认识Redis集群——Redis Cluster - JJian - 博客园 (cnblogs.com)](https://www.cnblogs.com/jian0110/p/14002555.html)\n\n### 配置文件\n\n```properties\n### REDIS CLUSTER  ###\n# 开启集群模式\ncluster-enabled yes\n# 设定节点配置文件名\ncluster-config-file nodes-6379.conf\n# 设定节点失联时间，超过该时间（毫秒），集群自动进行主从切换。\ncluster-node-timeout 15000\n\n# 如果处理某部分slot的主从都挂掉\n# yes - 整个集群挂掉\n# no - 挂掉slot的部分不可用，其它正常\ncluster-require-full-coverage yes\n```\n\n### 开启集群\n\n进入编译好的解压的redis目录`cd /opt/redis-6.2.10/src`\n\n执行以下命令，ip请使用真实ip\n\n```pseudocode\nredis-cli --cluster create --cluster-replicas 1 192.168.245.128:6379 192.168.245.128:6380 192.168.245.128:6381 192.168.245.128:6389 192.168.245.128:6390 192.168.245.128:6391\n```\n\n`--replicas 1` 采用最简单的方式配置集群，一台主机，一台从机。\n\n`-u` 账号\n\n`-a` 密码\n\n`redis-cli -c -p xxxx` 进入集群客户端\n\n- `-a xxx` 登录密码\n\n`cluster nodes` 查看集群节点信息\n\n**一个集群至少要有三个主节点。**\n\n选项 --cluster-replicas 1 表示我们希望为集群中的每个主节点创建一个从节点。\n\n分配原则尽量保证每个主数据库运行在不同的IP地址，每个从库和主库不在一个IP地址上。\n\n### slots\n\n一个 Redis **集群包含 16384 个插槽**（hash slot）， 数据库中的每个键都属于这 16384 个插槽的其中一个，集群使用公式 CRC16(key) % 16384 来计算键 key 属于哪个槽， 其中 CRC16(key) 语句用于计算键 key 的 CRC16 校验和 。\n\n**集群中的每个节点负责处理一部分插槽。** \n\n**在集群中录入数据:** \n\n- 每次录入、查询、Redis都会计算该key属于哪个插槽，并重定向到对应节点进行操作。\n\n- 不在一个slot下的键值，是不能使用mget,mset等多键批量操作。\n  - 可以使用{}对键进行分组，从而相同组的键值会被放入相同slot中。\n  - 例：`mset k1{group} v1 k2{group} v2 `\n\n\n\n`cluster keyslot <key>`  计算键 key 应该被放置在哪个槽上。\n\n`cluster countkeysinslot <slot>` 返回槽 slot 目前包含的键值对数量。\n\n`cluster getkeysinslot <slot> <count>` 返回 count 个 slot 槽中的键 。\n\n### 优缺点\n\n**优点：**\n\n- 实现扩容\n- 分摊压力\n- 无中心配置相对简单\n\n**缺点：**\n\n- 多键操作是不被支持的\n- 多键的Redis事务是不被支持的。lua脚本不被支持\n\n## 缓存穿透\n\nkey对应的数据在数据源并不存在，每次针对此key的请求从缓存获取不到，请求都会压到数据源，从而可能压垮数据源。比如用一个不存在的用户id获取用户信息，不论缓存还是数据库都没有，若黑客利用此漏洞进行攻击可能压垮数据库。\n\n## 缓存击穿\n\nkey对应的数据存在，但在redis中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。\n\n## 缓存雪崩\n\nkey对应的数据存在，但在redis中大量过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。\n\n缓存雪崩与缓存击穿的区别在于这里针对很多key缓存，前者则是某一个key\n\n正常访问\n\n## 分布式锁\n\n### setnx实现\n\n```java\npublic void pessimisticLock_setnx() {\n    boolean lock = false;\n    String uuid = UUID.randomUUID() + \":\" + Thread.currentThread().getId();\n    while (!lock) {\n        // 如果lock存在则已上锁 （lock名称自己定），set成功则返回true\n        lock = Boolean.TRUE.equals(redisTemplate.opsForValue().setIfAbsent(\"lock\", uuid, 3, TimeUnit.SECONDS));\n        if (lock) {\n            // 业务逻辑\n            redisTemplate.opsForValue().increment(\"exampleKey1\");\n            redisTemplate.opsForValue().decrement(\"exampleKey2\");\n            System.out.println(\"成功\");\n            if (uuid.equals(redisTemplate.opsForValue().get(\"lock\")))\n                redisTemplate.delete(\"lock\");\n        } else {\n            // 等待一下再发送请求\n            try {\n                Thread.sleep(10);\n            } catch (InterruptedException e) {\n                throw new RuntimeException(e);\n            }\n        }\n    }\n}\n```\n\n## Redisson\n\n### 引入依赖\n\n```xml\n<!-- https://mvnrepository.com/artifact/org.redisson/redisson-spring-boot-starter -->\n<dependency>\n    <groupId>org.redisson</groupId>\n    <artifactId>redisson-spring-boot-starter</artifactId>\n    <version>3.19.3</version>\n</dependency>\n```\n\n### 配置\n\n#### 方式一\n\n直接使用application.yml里spring.redis的配置信息。\n\nredisson和redis共用配置。\n\n#### 方式二\n\n直接写在application.yml里:\n\n```yaml\nspring:\n\tredis:\n\t\tredisson:\n\t\t\tconfig: \n\t\t\t\t#Redisson配置\n                singleServerConfig:\n                  address: \"redis://127.0.0.1:6379\"\n                  password: null\n                  clientName: null\n                  database: 0\n                  idleConnectionTimeout: 10000\n                  pingTimeout: 1000\n                  connectTimeout: 10000\n                  timeout: 3000\n                  retryAttempts: 3\n                  retryInterval: 1500\n                  reconnectionTimeout: 3000\n                  failedAttempts: 3\n                  subscriptionsPerConnection: 5\n                  subscriptionConnectionMinimumIdleSize: 1\n                  subscriptionConnectionPoolSize: 50\n                  connectionMinimumIdleSize: 32\n                  connectionPoolSize: 64\n                  dnsMonitoringInterval: 5000\n                  #dnsMonitoring: false\n\n                # 集群相关\n                clusterServersConfig:\n                  idleConnectionTimeout: 10000\n                  connectTimeout: 10000\n                  timeout: 3000\n                  retryAttempts: 3\n                  retryInterval: 1500\n                  password: null\n                  subscriptionsPerConnection: 5\n                  clientName: null\n                  loadBalancer: !<org.redisson.connection.balancer.RoundRobinLoadBalancer> {}\n                  slaveSubscriptionConnectionMinimumIdleSize: 1\n                  slaveSubscriptionConnectionPoolSize: 50\n                  slaveConnectionMinimumIdleSize: 32\n                  slaveConnectionPoolSize: 64\n                  masterConnectionMinimumIdleSize: 32\n                  masterConnectionPoolSize: 64\n                  readMode: \"SLAVE\"\n                  nodeAddresses:\n                  - \"redis://127.0.0.1:7004\"\n                  - \"redis://127.0.0.1:7001\"\n                  - \"redis://127.0.0.1:7000\"\n                  scanInterval: 1000\n\n                  threads: 0\n                nettyThreads: 0\n                codec:\n                  class: \"org.redisson.codec.JsonJacksonCodec\"\n                transportMode: \"NIO\"\n```\n\n[Redisson 分布式锁实战与 watch dog 机制解读 - 上帝爱吃苹果-Soochow - 博客园 (cnblogs.com)](https://www.cnblogs.com/keeya/p/14332131.html)\n\n## ACL\n\n`acl list`\n\n[Redis 6.0 访问控制列表ACL说明（有这篇就够了）_奇点_97的博客-CSDN博客](https://blog.csdn.net/qq_29235677/article/details/121475204)\n","tags":["笔记","Redis"],"categories":["Redis"]},{"title":"Linux学习笔记","url":"/2023/01/24/linux-note/","content":"# Linux学习笔记\n\nLinux学习记录，按照[韩顺平老师](https://space.bilibili.com/651245581 \"韩顺平 - Bilibili\")[视频](https://www.bilibili.com/video/BV1Sv411r7vd \"【小白入门 通俗易懂】2021韩顺平 一周学会Linux\")进行学习。\n\n## 目录结构\n\n> [Linux 系统目录结构 | 菜鸟教程](https://www.runoob.com/linux/linux-system-contents.html)\n\n### 基本介绍\n\n1. linux的文件系统是采用级**层式的树状**目录结构，在此结构中的最上层是**根目录“/”**。\n2.  在Linux世界里，一切皆文件。\n\n树状目录结构：\n\n```pseudocode\n/\n├── bin -> usr/bin\n├── boot\n├── dev\n├── etc\n├── home\n├── lib -> usr/lib\n├── lib64 -> usr/lib64\n├── lost+found\n├── media\n├── mnt\n├── opt\n├── proc\n├── root\n├── run\n├── sbin -> usr/sbin\n├── srv\n├── sys\n├── tmp\n├── usr\n└── var\n```\n\n![](https://www.runoob.com/wp-content/uploads/2014/06/d0c50-linux2bfile2bsystem2bhierarchy.jpg)\n\n### 目录解释\n\n- **/bin** [常用] (/usr/bin、 /usr/local/bin)是Binary的缩写，这个目录存放着最经常使用的命令\n- **/sbin** (/usr/sbin、 /usr/local/sbin)s就是Super User的意思，这里存放的是系统管理员使用的系统管理程序。\n- **/home** [常用]存放普通用户的主目录，在Linux中每个用户都有一个自己的目录，一般该目录名是以用户的账号命名\n- **/root** [常用]该目录为系统管理员，也称作超级权限者的用户主目录\n- **/lib** 系统开机所需要最基本的动态连接共享库，其作用类似于Windows里的DLL文件。几乎所有的应用程序都需要用到这些共享库\n- **/lost+found** 这个目录一般情况下是空的，当系统非法关机后，这里就存放了一些文件\n- **/etc**[常用]所有的系统管理所需要的配置文件和子目录,比如安装mysql数据库 my.conf\n- **/usr** [常用]这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似与windows下的program files目录。\n- **/boot** [常用] 存放的是启动Linux时使用的一些核心文件，包括一些连接文件以及镜像文件\n- **/proc** [不能动]这个目录是一个虚拟的目录，它是系统内存的映射，访问这个目录来获取系统信息\n- **/srv** [不能动]service缩写，该目录存放一些服务启动之后需要提取的数据\n- **/sys**[不能动]这是linux2.6内核的一个很大的变化。该目录下安装了2.6内核中新出现的一个文件系统 sysfs\n- **/tmp** 这个目录是用来存放一些临时文件的\n- **/dev**类似于windows的设备管理器，把所有的硬件用文件的形式存储/media[常用]linux系统会自动识别一些设备，例如U盘、光驱等等，当识别后，linux会把识别的设备挂载到这个目录下\n- **/mnt** [常用]系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将外部的存储挂载在/mnt/上，然后进入该目录就可以查看里的内容了。\n- **/opt** 这是给主机额外安装软件所摆放的目录。如安装ORACLE数据库就可放到该目录下。默认为空。\n- **/usr/local** [常用]这是另一个给主机额外安装软件所安装的目录。一般是通过编译源码方式安装的程序\n- **/var** [常用]这个目录中存放着在不断扩充着的东西,习惯将经常被修改的目录放在这个目录下。包括各种日志文件\n- **/selinux** [security-enhanced linux]SELinux是一种安全子系统，它能控制程序只能访问特定文件，有三种工作模式，可以自行设置.\n\n## Vim基本用法\n\nvim是vi的增强版，语法识别高亮显示等。。。\n\nvim <file> 用vim打开文件，没有则默认打开空文件\n\n### vim的三个模式\n\n- 一般模式\n- 输入模式\n- 命令行模式\n\n\n\n进入为一般模式，在一一般模式下按a/A，i/I，o/O按键进入输入模式，按Esc退回一般模式，在正常模式下按:进入命令行模式输入命令按Enter提交。\n\n{% mermaid %}\n\ngraph TD\n    EQ[进入/退出] --vim filename--> Normal[一般模式]\n    Normal --:wq--> EQ\n    Normal --输入i a o --> Input[输入模式]\n    Input --ESC--> Normal\n    Normal --输入 : --> Cmd[命令行模式]\n    Cmd --回车以结束运行--> Normal\n\n{% endmermaid %}\n\n### 一般模式指令\n\n- `yy` 复制当前行（`5yy`复制包括当前往下5行）\n- `p` 粘贴\n- `dd` 删除当前行（`5dd`删除包括当前往下5行）\n- `gg` 光标跳到第一行\n- `G` 光标跳到最后一行\n- `<行号>gg/<行号>G` 光标跳到指定行（例如：`20gg/20G`跳转到行号20）\n- `/<关键词>` 搜索关键词，`n`查找下一个（例如`/hello`）\n\n### 命令行模式指令\n\n- `:h` 查看help.txt\n\n- `:w` 保存写入\n- `:q` 退出\n- `:q!` 强制退出\n- `:wq` 保存写入并退出\n- `:<行号>` 跳转到指定行号（如：`:20` 跳转到行号20）\n- `:set nu` 临时设置行号\n- `:set nonu` 取消行号\n\n### Vim键盘图\n\n![](https://www.runoob.com/wp-content/uploads/2015/10/vi-vim-cheat-sheet-sch.gif)\n\n## 用户管理\n\n### 相关指令（命令）\n`su - <user>` 切换用户\n\n`logout` / `exit` 登出\n\n`id <user>` 查看用户信息\n\n`whoami` 查看当前会话用户\n\n`who am i` 查看登录的用户信息 （第一次会话的）\n\n\n\n`useradd <user>` 创建用户\n\n- `-r` 指定家目录\n- `-g` 添加到指定用户组（不添加将创建与该用户同名的组，并指定该组）\n\n`passwd <user>` 修改用户密码\n\n`userdel <user>` 删除用户\n\n- `-r` 同时删除家目录\n\n`usermod [选项] <user>` 修改用户属性\n\n- `-g` 修改用户组\n- `-d` 修改用户家目录（需要有一定权限）\n\n\n\n`groupadd <group>` 创建用户组\n\n`groupdel <group>` 删除用户组\n\n\n\n### 用户和组相关文件\n\n/etc/passwd文件\n\n- 用户的配置文件，记录用户的各种信息\n- 每行格式： 用户名:口令:用户标识号:组标识号:注释性描述:主目录:Shell登录\n\n/etc/shadow文件\n\n- 口令的配置文件\n- 每行格式： 用户名:加密口令:最后一次修改时间:最小时间间隔:最大时间间隔:警告时间:不活动时间:失效时间:标志\n\n/etc/group文件\n\n- 组的配置文件，记录Linux包含的组的信息\n- 每行格式： 组名:口令:组标识号:组内用户列表\n\n### 忘记密码解决办法\n\n**基于CentOS 7.9**\n\n1. 重启系统\n2. 在选择界面使用方向上下键选择防止自动选择\n3. 按**e**进入编辑界面\n4. 找到以linux16开头的行，在末尾加入`init=/bin/sh`\n5. Ctrl+X进入单用户模式\n6. 输入：`mount -o remount,rw /`并回车 \n7. 输入：`passwd`并回车\n8. 输入两遍新密码\n9. 输入：`touch /.autorelabel`并回车\n10. 输入：`exec /sbin/init` 并回车\n11. 等待系统重启即可\n\n> 其它操作修改： [Linux系统忘记了root密码怎么办？_Dribblelife的博客-CSDN博客_忘记root密码](https://blog.csdn.net/weixin_38044888/article/details/89915553)\n\n## <span id=\"runLevel\">运行级别</span>\n\n### 基本介绍\n\n运行级别说明：\n\n- 0:关机\n- 1:单用户【找回丢失密码】\n- 2：多用户状态没有网络服务\n- 3：多用户状态有网络服务\n- 4：系统未使用保留给用户\n- 5：图形界面\n- 6：系统重启\n\n常用运行级别是3和5，也可以指定默认运行级别\n\n演示应用实例命令：**`init [0123456]`** \n\n应用案例：通过init 来切换不同的运行级别，比如动 5-3，然后关机。\n\n- `systemctl get-default` 查看默认运行级别\n- `systemctl set-default <级别>` 设置默认运行级别\n  - `multi-user.target` 多用户级别 3\n  - `graphical.target` 图形级别 5\n\n## 帮助指令\n\n- `man <命令或配置文件>` 获得帮助信息（`man ls`查看`ls`命令的帮助信息）\n- `help [命令]` 获取shell内置命令的帮助信息（如`help cd`）\n- `<命令> --help` 查看某命令的帮助信息（如`ls --help`）\n\n## 文件目录指令\n\n`pwd` 显示当前工作目录的绝对路径\n`ls [选项] [目录/文件]` 查看显示目录/文件信息\n\n- `-a` 显示当前目录所有的文件和目录，包括隐藏的\n- `-l` 已列表的方式显示信息（等同于ll）\n- `-i `\n- `-h` 转换大小单位\n\n`cd <dir>` 切换到指定目录\n\n  - `cd ~` 切换到家目录\n  - `cd ..` 返回上一级目录\n\n\n\n`mkdir [选项] <目录>` 创建目录\n\n- `-p` 创建多级目录\n\n`rmdir <目录>` 删除空目录\n`rm [选项] <文件/目录>` 删除目录/文件\n\n- `-r` 递归删除整个目录\n- `-f` 强制删除不提示\n- `-rf` 包含上面两者\n\n`touch <file>` 创建一个空文件\n\n`cp [选项] <source> <dest>` 复制文件/目录到指定目录\n\n- `-r` 递归复制整个目录\n- `\\cp` 强制覆盖不提示\n\nmv 移动文件与目录或重命名\n\n- `mv <oldName> <newName>` 重命名\n- `mv <file/dir> <path>` 移动文件/目录\n\n\n\n`cat [选项]` 查看文件内容\n\n- `-n` 显示行号\n- `cat [选项] <file> | more `\n\n\n\nmore 基于VI编辑器的文本过滤器，以全屏幕的方式按页显示\n\n- Space  翻动下一页\n- Enter  翻动下一行\n- q 退出\n- Ctrl+F 翻动下一屏\n- Ctrl+B 翻动上一屏\n- = 输出当前行的行号\n- :f 输出文件名和当前行的行号\n\nless 分屏查看文件内容，与more类似但更强大，按需加载\n\n- Space  翻动下一页\n- PageDown 翻动下一页\n- PageUp 翻动上一页\n- /<keyword> 向下搜寻。 n：下一个 N：上一个\n- ?<keyword> 向上搜寻。 n：下一个 N：上一个\n- q 退出\n\n\n\n`echo [选项] <content>`  输出内容到控制台\n\n- 如 `echo $HOSTNAME` 输出主机名\n- 如 `echo $PATH` 输出环境变量\n\n`head [选项] <file>` 显示文件的头部内容，默认前十行\n\n- `-n <lines>` 显示前多少行\n- `-c  <bytes>` 显示前多少字节\n\n`tail [选项] <file>` 显示文件的尾部内容，默认后十行\n\n- `-n <lines>` 显示后多少行\n- `-c  <bytes>` 显示后多少字节\n- `-f` 实时监控文件变化\n\n\n\n'>' 输出重定向（覆盖）\n\n'>>' 追加\n\n- `ls -l > 文件` 列表的内容覆盖到文件\n- `ls -al >> 文件` 列表的内容追加到文件\n- `cat 文件1 > 文件2` 将文件1的内容覆盖到文件2\n- `echo \"内容\"  >> 文件` 追加内容到文件\n\n\n\nIn指令：软链接也称为符号链接，类似于windows里的快捷方式，主要存放了链接其他文件的路径\n\n- `ln -s <原文件/目录> <软链接名>` 给原文件/目录创建一个软链接（pwd查看仍在原文件/目录）\n\n\n\n`history [数量]` 查看已经执行过的历史命令，无参默认显示全部\n\n- `!<编号>` 执行历史命令中编号为<编号>的命令（如!5 执行编号为5的命令）\n\n## 时间日期指令\n\n`date` 显示当前时间\n`date +%Y` 显示当前年份\n`date +%m` 显示当前月份\n`date +%d` 显示当前是哪一天\n`date \"+%Y-%m-%d %H:%M:%S\"` 显示年月日时分秒\n`date -s <字符串时间>` 设置系统当前时间\n\n\n\n`cal [选项]` 显示当前日历，无参默认显示当前时间日历\n\n- `cal 2023` 显示2023年日历\n\n## 搜索查找指令\n\n`find [范围] [选项]` 从指定目录向下递归遍历其各个子目录查找\n\n- `-name <name>` 按照指定的文件名查找\n- `-user <user>` 查找属于指定用户名的所有文件\n- `-size <size> `按照指定的文件大小查找文件（单位K，M，G）\n  - `find / -size +200M `查找/下大于200M的文件，-200M表示小于200M的文件\n\n`locate <file>` 可以快速定位文件路径。\n\n- locate指令利用事先建立的系统中所有文件名称及路径的locate数据库实现快速定位给定的文件。\n- locate指令无需遍历整个文件系统,查询速度较快。\n- 为了保证查询结果的准确度，管理员必须定期更新locate时刻\n- `updatedb` 更新数据库\n\n`which <cmd>` 查询某个指令在哪个目录下\n\n\n\n`grep [选项] <内容> <源文件>` 过滤查找\n\n- `-n` 显示匹配行及行号\n- `-i` 忽略字母大小写\n\n\n\n`|`管道符 ，将前一个命令查询到的内容交给下一个命令\n\n- `cat a.txt | grep \"hello\"`    cat查询到的内容交给grep进行过滤查找\n\n## 压缩和解压\n\n`gzip <file>` 只能将文件压缩成.gz文件\n\n`gunzip <file.gz>` 解压.gz文件\n\n\n\n`zip [选项] <name.zip> <file/dir>` 压缩成name.zip文件\n\n- `-r` 递归压缩，即压缩目录\n\n`unzip [选项] <file.zip>` 解压\n\n- `-d <dir>` 指定解压后存放目录\n\n\n\n`tar [选项]` 打包、压缩或解压\n\n- `-c` 产生.tar打包文件\n- `-v` 显示详细信息\n- `-f` 指定压缩后的文件名\n- `-z` 通过gzip指令处理压缩解压\n- `-j` 通过bzip2指令处理压缩解压\n- `-x` 解包.tar文件\n- `-C` 指定解压目录\n- 常见用法\n  - `tar -czvf <xxx.tar.gz> <file>...` 压缩成.tar.gz\n  - `tar -xzvf <xxx.tar.gz>` 解压\n  - `tar -tzvf <xxx.tar.gz>` 列出压缩文件内容\n\n> [Linux tar 命令 |  菜鸟教程](https://www.runoob.com/linux/linux-comm-tar.html)\n\n## Linux组(权限)\n\n### 基本内容\n\n在linux中的每个用户必须属于一个组，不能独立于组外。在linux中每个文档/文件有所有者、所属组、其它组的概念。\n\n\n\n`ls -ahl`显示格式解释如下：\n\n| 文档/文件属性 | 链接数 | 所有者  | 所属组  | 大小 |   修改时间    |\n| :-----------: | :----: | :-----: | :-----: | :--: | :-----------: |\n|  drwx------.  |   16   | wshape1 | wshape1 | 4.0K | 1月  25 14:17 |\n|  -rw-r--r--.  |   1    |  root   |  root   | 15K  | 1月  25 17:03 |\n\n![](https://www.runoob.com/wp-content/uploads/2014/06/file-llls22.jpg)\n\n文档属性：\n\n- 第一位：表示文档类型\n  - d 目录\n  - -文件\n  - l 链接文档\n  - b 装置文件里面的可供储存的接口设备(可随机存取装置)（块文件）\n  - c 装置文件里面的串行端口设备，例如键盘、鼠标(一次性读取装置)（字符设备）\n- 第2到4位：所有者权限\n- 第3到5位：所属组权限\n- 第6到8位：其他组权限\n\n![](https://www.runoob.com/wp-content/uploads/2014/06/363003_1227493859FdXT.png)\n\n**rwx作用到文件**\n\n1. [**r**]代表可读(read):可以读取,查看字\n2. [**w**]代表可写(write)：可以修改，但是不代表可以删除该文件,删除一个文件的前提条件是对该文件所在的目录有写权限，才能删除该文件.\n3. [**x**]代表可执行(execute):可以被执行\n\n**rwx作用到目录**\n\n1. [**r**]代表可读(read)：可以读取，Is查看目录内容 （但是不能进入目录）\n2. [**w**]代表可写(write)： 可以修改,对目录内创建+删除+重命名目录\n3. [**x**]代表可执行(execute)：可以进入该目录 （但是不能查看目录内容）\n\n\n\n### 常用指令\n\n`chown [选项] <user> <file/dir>` 修改文件/目录所有者\n\n- `chown [选项] <newOwner>:<newGroup> <file/dir>` 同时修改所有者与所属组\n\n`chgrp [选项] <group> <file/dir>` 修改文件/目录所在组 \n\n`chmod [选项] <权限> <file/dir>` 修改文件/目录权限\n\n- rwx方式变更权限u：所有者，g：所属组，o：其它组，a：所有人（u g o的总和）\n  - 例：`chmod u=rwx, g=rx, o=x <文件/目录>` 给u g o分别赋予rwx rx x权限\n  - 例：`chmod o+w <文件/目录>` 给o增加w权限\n  - 例：`chmod a-x <文件/目录>` 给a移除x权限\n- 数字方式变更权限r=4 w=2 x=1，rwx=4+2+1=7\n  - 例：`chmod 751<文件/目录>` 等同于u=rwx, g=rx, o=x\n\n\n\n以上三个指令共有选项：\n\n- -R 递归修改目录内内容权限\n\n\n\n修改权限后用户仍无法控制则可能需要重新登陆\n\n## 定时任务调度\n\n**任务调度**：是指系统在某个时间执行的特定的命令或程序。\n\n**任务调度分类**:\n\n1. 系统工作:有些重要的工作必须周而复始地执行。如病毒扫描等\n2. 个别用户工作：个别用户可能希望执行某些程序，比如对mysql数据库的备份\n\n### crond任务调度\n\n>  [Linux crontab 命令 | 菜鸟教程](https://www.runoob.com/linux/linux-comm-crontab.html)\n\n`crontab [选项]`\n\n- `-e` 编辑定时任务\n- `-l` 查询定时任务\n- `-r` 删除当前用户所有的定时任务\n\nservice crond restart 重启crond\n\n\n\n**调度文件：**\n\n- 文件内容格式：`f1 f2 f3 f4 f5 program`  f1--5为时间格式program为执行程序\n\n- 时间占位符（时间格式）\n\n  ```pseudocode\n  *    *    *    *    *\n  -    -    -    -    -\n  |    |    |    |    |\n  |    |    |    |    +----- 星期中星期几 (0 - 6) (星期天 为0)\n  |    |    |    +---------- 月份 (1 - 12) \n  |    |    +--------------- 一个月中的第几天 (1 - 31)\n  |    +-------------------- 小时 (0 - 23)\n  +------------------------- 分钟 (0 - 59)\n  ```\n\n- 时间格式特殊符号\n  \n  \n  | 特殊符号 | 含义                                                         |\n  | -------- | ------------------------------------------------------------ |\n  | *        | 代表任何时间。比如第一个“*”就代表一小时中每分钟都执行一次的意思。 |\n  | ,        | 代表不连续的时间。比如“0 8,12,16 * * * 命令”，就代表在每天的8点0分，12点0分，16点0分都执行一次命令 |\n  | -        | 代表连续的时间范围。比如\"05 * * 1-6命令\" ,代表在周一到周六的凌晨5点0分执行命令 |\n  | */n      | 代表每隔多久执行一次。比如“*/10 * * * * 命令”，代表每隔10分钟就执行一遍命令 |\n\n\n\n### at定时任务\n\n1. at命令是一次性定时计划任务,at的守护进程atd会以后台模式运行,检查作业队列来运行。\n2. 默认情况下，atd守护进程每60秒检查作业队列，有作业时，会检查作业运行时间，如果时间与当前时间匹配，则运行此作业。\n3. at命令是一次性定时计划任务，执行完一个任务后不再执行此任务了。\n4. 在使用at命令的时候,一定要保证atd进程的启动,可以使用相关指令（`ps -ef | grep atd`）来查看。\n\n\n\n`at [选项] [时间]` 设置定时任务 （Ctrl+D结束命令输入）\n\n- `-m` 当指定的任务被完成后，将给用户发送邮件，即使没有标准输出\n- `-I` 显示待执行任务的列表 (同atq命令)\n- `-d` 删除指定的待执行任务（同atrm命令）\n- `-v` 显示任务将被执行的时间\n- `-c` 打印任务的内容到标准输出\n- `-V` 显示版本信息\n- `-q <队列>` 使用指定的队列\n- `-f <文件>` 从指定文件读入任务而不是从标准输入读入\n- `-t <时间参数>` 以时间参数的形式提交要运行的任务\n\n时间表达式：\n\n- YYMMDDhhmm[.ss]（缩写年、月、日、小时、分钟[秒]）\n- CCYYMMDDhhmm[.ss]（完整年、月、日、小时、分钟和[秒]）\n- now\n- midnight\n- noon\n- teatime (4:00PM)\n- tomorrow\n- AM\n- PM\n- 可以添加一个+使它们相对于某个时间，下面是可用单位：\n  - minutes\n  - hours\n  - days\n  - weeks\n  - months\n  - years\n\n```pseudocode\n$ echo \"rsync -av /home/tux me@myserver:/home/tux/\" | at 3:30 AM tomorrow\n$ echo \"/opt/batch.sh ~/Pictures\" | at 3:30 AM 08/01/2022\n$ echo \"echo hello\" | at now + 3 days\n```\n\n>  [Linux at命令详解 - 许良Linux](https://www.cnblogs.com/yychuyu/p/15483186.html)\n\n## 磁盘管理\n\n\n\n### 磁盘分区\n\n**原理介绍:**\n\n1. Linux来说无论有几个分区，分给哪一目录使用，它归根结底就只有一个根目录，一个独立且唯一的文件结构，Linux中每个分区都是用来组成整个文件系统的一部分。\n2. Linux采用了一种叫“载入”的处理方法,它的整个文件系统中包含了一整套的文件和目录，且将一个分区和一个目录联系起来。这时要载入的一个分区将使它的存储空间在一个目录下获得。\n\n**硬盘说明：**\n\n1. Linux硬盘分IDE硬盘和SCSI硬盘，目前基本上是SCSI硬盘\n2. 对于IDE硬盘,驱动器标识符为\"hdx~\",其中\"hd\"表明分区所在设备的类型,这里是指IDE硬盘了。\"x”为盘号（a为基本盘，b为基本从属盘，c为辅助主盘，d为辅助从属盘），\"~”代表分区前四个分区用数字1到4表示，它们是主分区或扩展分区，从5开始就是逻辑分区。例，hda3表示为第一个IDE硬盘上的第三个主分区或扩展分区,hdb2表示为第二个IDE硬盘上的第二个主分区或扩展分区。\n3. 对于SCSI硬盘则标识为“sdx~”,SCSI硬盘是用“sd\"来表示分区所在设备的类型的，其余则和IDE硬盘的表示方法一样。\n\n\n\n**查看所有设备挂载情况**\n\n- `lsblk`\n\n- `lsblk -f`\n\n\n\n**分区命令：**\n\n- `fdisk /dev/sdx `\n- 开始对/sdx分区\n  - m 显示命令列表\n  - p 显示磁盘分区\n  - n 新增分区\n  - d 删除分区\n  - w 写入并退出\n\n**格式化磁盘：**\n\n`mkfs -t <分区类型> /dev/sdx~`\n\n- 分区类型：ext2、ext3、ext4、reiserfs、nfs、vfat\n\n**挂载分区：**\n\n`mount <设备> <目录>`\n\n- `mount /dev/sdx~ <dir>`\n\n- **重启系统后失效**\n\n- **永久挂载分区：**\n\n  - 修改/etc/fstab \n\n  - 添加行，行格式：`UUID或者设备名称 挂载目录 分区类型 文件系统的参数 能否被dump备份命令作用 是否检测扇区 `\n    如：`/dev/sdx~ /newdisk ext4 defaults 0 0 `\n\n  - 执行mount -a 或重启系统\n\n  - > [/etc/fstab文件的详解_韩帅平的博客-CSDN博客_/etc/fstab](https://blog.csdn.net/youmatterhsp/article/details/83933158)\n\n**卸载分区：**\n\n`umount <设备>`\n\n`umount <被挂载目录>`\n\n### 磁盘使用情况\n\n`df -Th` 查看整体磁盘使用情况\n\n`du [选项] [dir]` 查看指定目录的磁盘使用情况，默认为当前目录\n\n- `-s` 指定目录占用大小汇总\n\n- `-h` 带计量单位\n\n- `-a` 含文件\n\n- `--max-depth=1` 子目录深度\n\n- `-c` 列出明细的同时，增加汇总值\n\n- > [Linux 磁盘管理 | 菜鸟教程 (runoob.com)](https://www.runoob.com/linux/linux-filesystem.html)\n\n### 实用指令\n\n1. 统计/opt文件夹下文件的个数\n   `ls -l /opt | grep \"^-\" | wc -l`\n2. 统计/opt文件夹下目录的个数\n   `ls -l /opt | grep \"^d\" | wc -l`\n3. 统计/opt文件夹下文件的个数，包括子文件夹里的\n   `ls -lR /opt | grep \"^-\" | wc -l`\n4. 统计/opt文件夹下目录的个数，包括子文件夹里的\n   `ls -lR /opt | grep \"^d\" | wc -l`\n5. 以树状显示目录结构tree目录，可能需要执行`yum install tree`安装\n\n> [Linux wc命令 | 菜鸟教程 (runoob.com)](https://www.runoob.com/linux/linux-comm-wc.html)\n\n\n\n## 网络配置\n\nNAT(Network Address Translation)网络配置\n\n{% mermaid %}\n\nflowchart LR\n\tsubgraph 电脑Windows\n\t\tlinux(Linux虚拟\\n192.168.245.128) --> vmnet(VMnet8\\n192.168.245.1)\n        vmnet --> linux\n        wk([无线网卡\\n192.168.31.122])\n        vmnet --> wk\n\tend\n\tsubgraph 局域网\n\t\twk --> wg(网关)\n\tend\n\twg --> three[互联网\\nbaidu.com\\n...]\n\n{% endmermaid %}\n\n`ifconfig` 查看网络配置\n\n`ping <ip>` 测试当前主机是否可以于目标ip进行通讯\n\n\n\n### IP配置\n\n- 自动获取：\n\n  - 登陆后，通过界面的来设置自动获取ip\n  - 特点：linux启动后会自动获取IP\n  - 缺点是每次自动获取的ip地址可能不一样。\n\n- 手动配置：\n\n  - 图形化：网络设置里配置\n\n  - 直接修改配置文件来指定IP并可以连接到外网(程序员推荐)\n    - 编辑/etc/sysconfig/network-scripts/ifcfg-ens33（如修改为192.168.245.2）\n      - 修改IPV4配置方式`BOOTPROTO=\"static\"`\n      - 修改IP地址`IPADDR=192.168.245.128`\n      - 修改网关`GATEWAY=192.168.245.2`\n      - 修改DNS`DNS=192.168.245.2`\n      - 虚拟机的记得要配置虚拟机网络相关配置\n      - `service network restart`或重启系统\n\n### 主机名与hosts映射\n\n**查看主机名：**\n\n- `hostname`\n\n**修改主机名：**\n\n- 修改文件/etc/hostname\n- 重启系统\n\n**修改hosts映射：**\n\n- 编辑配置文件/etc/hosts\n- 行格式：`ip  域名(主机名)`\n\n## 进程管理\n\n在Linux中，每个执行的程序都称为一个进程。每一个进程都分配一个ID号(pid,进程号)。\n\n每个进程都可能以两种方式存在的。前台与后台，所谓前台进程就是用户目前的屏幕上可以进行操作的。后台进程则是实际在操作，但由于屏幕上无法看到的进程，通常使用后台方式执行。\n\n\n\n`ps [选项]` 显示目前系统正在运行的程序\n\n- `-a ` 显示当前终端的所有进程信息\n- `-u` 以用户的格式显示进程信息\n- `-x` 显示后台进程运行的参数\n- `-w` 不限制输出宽度\n- `-e` 显示所有进程\n- `-f` 全格式输出，包括命令\n- 寻找指定进程：`ps -ef | grep <关键词>`\n- `ps -aux`输出格式：`USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND`\n  - USER: 进程执行用户\n  - PID: 进程号\n  - %CPU: 占用的 CPU 使用率\n  - %MEM: 占用的物理内存使用率\n  - VSZ: 占用的虚拟内存大小 (KB)\n  - RSS: 占用的物理内存大小 (KB)\n  - TTY: 终端的次要装置号码 (minor device number of tty)\n  - STAT: 该行程的状态:\n    - D: 无法中断的休眠状态 (通常 IO 的进程)\n    - R: 正在执行中 running\n    - S: 静止状态 sleep\n    - T: 暂停执行\n    - Z: 不存在但暂时无法消除（僵尸进程）\n    - W: 没有足够的内存分页可分配\n    - <: 高优先序的进程\n    - N: 低优先序的进程\n    - L: 有内存分页分配并锁在内存内 (实时系统或捱A I/O)\n  - START: 进程开始时间\n  - TIME: 执行的时间\n  - COMMAND:所执行的指令（过长会被截断）\n\n**父子进程**\n\n- ps -ef 查看 \n- PPID表示父进程pid\n\n**终止进程**\n\n- `kill [选项] <pid>` 终止进程\n  - `-9` 强制终止进程\n- `killall <程序名>` 通过进程名称杀死进程，也支持通配符，这在系统因负载过大而变得很慢时很有用\n\n**查看进程树**\n\n- `pstree [选项]` 查看进程树\n  - `-p` 显示进程的PID\n  - `-u` 显示进程的所属用户\n\n### 动态进程管理\n\n`top [选项]` 实时更新显示进程\n\n- `-d <秒>` 指定更新间隔\n- `-i` 不显示任何闲置或者僵尸进程\n- `-p <pid>` 监控指定pid的进程 \n- `-n` 更新几次后退出\n\n显示头：\n\n```pseudocode\ntop - 11:13:24 up 37 min,  1 user,  load average: 0.00, 0.01, 0.03\nTasks: 224 total,   1 running, 223 sleeping,   0 stopped,   0 zombie\n%Cpu(s):  0.0 us,  0.1 sy,  0.0 ni, 99.9 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\nKiB Mem :  2027680 total,  1168104 free,   478228 used,   381348 buff/cache\nKiB Swap:  2097148 total,  2097148 free,        0 used.  1389524 avail Mem \n\n   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND\n```\n\n**交互操作：**\n\n- `P`以%CPU排序，默认就是此项\n- `M`以%MEM排序\n- `N`以PID排序\n- `u` 查看指定用户的进程\n- `k` 删除指定PID的进程\n- `q` 退出\n\n### 服务管理\n\n服务(service)本质就是进程，但是是运行在后台的，通常都会监听某个端口，等待其它程序的请求，比如（mysqld，sshd 防火墙等），因此我们又称为守护进程，是Linux中非常重要的知识点。\n\n#### service管理指令\n\n- `service <服务名> <start | stop | restart | reload | status>`\n\nservice指令管理的服务在/etc/init.d/查看（`ll /etc/init.d/`）\n\n**查看系统服务**\n\n- `setup`\n\n**开机流程：**\n\n{% mermaid %}\n\ngraph LR\n    开机 ==> BIOS ==> /boot ==> systemd进程 ==> 运行级别 ==> 运行级别对应的服务\n\n{% endmermaid %}\n\n跳转查看[运行级别](#runLevel)解释\n\n\n\n#### chkconfig指令  \n\n管理服务在各个运行级别的自启动\n\nchkconfig 指令管理的服务在/etc/init.d/ 查看\n\n基本用法：\n\n- `chkconfig --list` 查看服务\n- `chkconfig <服务名> --list` 查看某个服务\n- `chkconfig --level <运行级别> <服务名> <on | off> ` 设置\n\n**重启系统生效**\n\n#### systemctl管理指令\n\nsystemctl指令管理的服务在**/usr/lib/systemd/system/**查看(`ll /usr/lib/systemd/system/`)\n\nsystemctl简化了运行级别，只有3和5\n\n**基本用法：**\n\n- `systemctl <start | stop | restart | status> <服务名>` 开启/关闭/重启/查询 服务\n- `systemctl list-unit-files` 查看服务开机启动状态(是否开机自启)\n- `systemctl <enable | disable> <服务名>` 开启/关闭服务开机自启动\n- `systemctl is-enabled <服务名>`查询某个服务是否是自启动的\n\n#### <span id=\"firewall\">防火墙端口指令</span>\n\n`firewall-cmd --permanent --add-port=端口号/协议` 打开端口\n\n`firewall-cmd --permanent --remove-port=端口号/协议` 关闭端口\n\n`firewall-cmd --reload` 重新载入,才能生效\n\n`firewall-cmd --query-port=端口/协议 ` 查询端口是否开放\n\n### 系统网络情况netstat\n\n`netstat [选项]`\n\n- `-an` 按一定顺序输出排列\n- `-p` 显示哪个进程在调用\n\n## rpm和yum包管理\n\n### RPM\n\n`rpm [选项]` rpm包管理指令\n\n- `-qa` 查询所有已安装的rpm软件包\n- `-q <name>` 查询指定的软件包是否安装\n- `-qi <name>` 查询指定软件包的信息\n- `-ql <name>` 查询指定软件包的文件\n- `-qf <文件全路径名>` 查询文件所属的软件包\n- `-e <name>` 删除指定软件包（`--nodeps` 强制删除）\n- `-ivh <file>` 安装软件包（-i安装，-v提示，-h进度条）\n\n### YUM\n\nYum是一个Shell前端软件包管理器。基于RPM包管理,能够从指定的服务器自动下载RPM包并且安装，**可以自动处理依赖性关系**，并且一次安装所有依赖的软件包。\n\n`yum [选项]` yum包管理指令\n\n- `list` 查看服务器支持的包列表（可以使用grep过滤）\n- `install <name>` 下载安装指定软件包\n- `check-update`  检查是否有可用的软件包更新\n- `update [name]` 更新系统中的一个或多个软件包\n\n[linux yum 命令 | 菜鸟教程 (runoob.com)](https://www.runoob.com/linux/linux-yum.html)\n\n## 搭建JavaEE环境\n\n### 安装JDK\n\n[Java Downloads | Oracle 中国](https://www.oracle.com/cn/java/technologies/downloads/)\n\n1. yum安装\n   - `yum list java*` 查看服务器jdk版本列表\n   - `yum install java-x.x.x-openjdk` 安装指定版本\n2. rpm安装\n   - 下载指定版本JDK的rpm安装包\n   - `rpm -ivh <file>` 等待安装完成即可\n   - 默认安装在/usr/lib/jvm\n3. 压缩包安装(以JDK17为例)\n   - 下载安装包到/opt （其它目录也行），并进入/opt\n   - 解压 `tar -zxvf jdk-17_linux-x64_bin.tar.gz`\n   - 创建文件夹`mkdir /usr/local/java`\n   - 移动jdk `mv jdk-17.0.6/ /usr/local/java/ `\n   - 配置环境变量 `vim /etc/profile`在文件末尾添加以下内容：\n     - `export JAVA_HOME=/usr/local/java/jdk-17.0.6`\n     - `export PATH=$JAVA_HOME/bin:$PATH`\n   - 执行`source /etc/profile` 使配置生效，或者重启系统\n\n### 安装Tomcat\n\n[Apache Tomcat® - Apache Tomcat 9 Software Downloads](https://tomcat.apache.org/download-90.cgi)\n\n1. yum安装\n   - `yum install tomcat`\n   - `systemctl <start | stop> tomcat.service` 启动/关闭\n2. 压缩包安装（以Tomcat9为例）\n   - 下载Tomcat9至/opt目录（可以是其它目录）\n   - 执行`tar -zxvf apache-tomcat-9.0.71.tar.gz `解压\n   - 进入/apache-tomcat-9.0.71/bin `cd apache-tomcat-9.0.71/bin/`\n   - 执行`./startup.sh`启动Tomcat\n   - 注意Linux防火墙是否拦截8080端口（[指令设置](#firewall)）\n   - 如需设置环境变量，方法如上\n   - 执行`./shutdown.sh`关闭Tomcat\n\n### 安装MySql\n\n[MySQL :: Download MySQL Community Server](https://dev.mysql.com/downloads/mysql/)\n\n1. rpm安装（以8.0为例）\n   - 下载rpm安装包到指定文件夹 （bundle后缀的文件）\n   - 查询是否有mariadb，如有则卸载\n     - `rpm -qa | grep mariadb` 查询\n     - `rpm -e --nodeps mariadb-libs`卸载\n   - 解压bundle `tar -xvf  mysql-8.0.32-1.el7.x86_64.rpm-bundle.tar`\n   - 依次安装：\n     - *`rpm -ivh mysql-community-common-8.0.32-1.el7.x86_64.rpm`\n     - `rpm -ivh mysql-community-client-plugins-8.0.32-1.el7.x86_64.rpm`\n     - *`rpm -ivh mysql-community-libs-8.0.32-1.el7.x86_64.rpm`\n     - *`rpm -ivh mysql-community-client-8.0.32-1.el7.x86_64.rpm`\n     - `rpm -ivh mysql-community-icu-data-files-8.0.32-1.el7.x86_64.rpm`\n     - *`rpm -ivh mysql-community-server-8.0.32-1.el7.x86_64.rpm`\n   - 初始root密码查看`grep password /var/log/mysqld.log`\n   - 启动MySql服务 `systemctl start mysqld.service`\n   - 进入MySql并修改初始密码\n     - `mysql -u root -p`\n     - `ALTER USER root@localhost IDENTIFIED BY '密码';`\n\n### 安装Redis\n\n> [Zookeeper学习笔记 | Wshape1's Blogs](https://wshape1.github.io/2023/02/21/zookeeper-note/)\n\n## Shell入门\n\n","tags":["Linux","笔记"],"categories":["Linux"]},{"title":"快速幂算法(例:a^b mod p)","url":"/2022/07/15/fast_power/","content":"\n# 介绍\n\n**快速幂**（**Exponentiation by squaring**，平方求幂）是一种简单而有效的小算法，它可以以O(log n)的时间复杂度计算乘方。快速幂不仅本身非常常见，而且后续很多算法也都会用到快速幂。\n\n### 为什么要使用快速幂？\n\n比如要计算以下式子：\n$$\n9^{10}=?\n$$\n传统算法是\n$$\n9^{10} = 9*9*9*9*9*9*9*9*9*9\n$$\n计算机要通过**9次**计算才能得出答案。而快速幂的方法就是通过平方来减少计算次数：\n$$\n9^{10}=(9*9)^{5}=(81*81)^{2}*81\n$$\n这样子就只需要**4次**。\n\n这样的时间复杂度是**O(log n)**，当次方很大时可以节省很多时间。\n\n### 算法实现\n\n##### 非递归版\n\n```pseudocode\nfast_power(a, b)\n\tans = 1\n    while(b)\n        if b % 2 == 1\t//当幂为奇数时\n            ans *= a\n            b -= 1\n        else\n            a *= a\n            b /= 2\n    return ans\n```\n\n在b % 2 == 1运行完成后，b必定是偶数，接下来会再次进行while循环进入到else里面，其实我们可以简化成一次循环，如下：\n\n```pseudocode\nfast_power(a, b)\n\tans = 1\n    while(b)\n        if b % 2 == 1\n            ans *= a\n        a *= a\n        b /= 2\n    return ans\n```\n\n##### 递归版（慎用）\n\n```pseudocode\nfast_power(a, b)\n\tif b <= 0\n    \treturn 1\n    if b % 2 == 1\t//当幂为奇数时\n    \tans = fast_power(a, b - 1) * a\n    else \n    \tans = fast_power(a * a, b / 2)\n    return ans\n```\n\n以上都要**注意变量a, b, ans的范围**。\n\n### 例题a^b\n\n\n\n题目：[牛客网](https://ac.nowcoder.com/acm/contest/996/A \"a^b\")\n$$\n求 a 的 b 次方对 p 取模的值，其中 0≤a,b,p≤10^9，p>0\n$$\n**输入描述：**\n\n> 三个用空格隔开的整数a,b和p。\n\n**输出描述：**\n\n> 一个整数，表示a^b mod p的值。\n\n##### **思路：**\n\n1. 最直接的思路就是算出a^b的值之后再模p，不管是否上述快速幂的方法，都存在一个很明显问题是 a^b 的范围大至10的9次方的10的9次方，**远超过了long long的范围**。\n\n2. 利用**快速幂+取模运算的性质**，可以快速的同时不会让数值超过范围，性质**(a * b) % p = (a % p * b % p) % p** \n\n   于是可以得到以下代码：\n\n   ```c++\n   typedef long long ll;\n   ll fast_power(ll a, ll b, ll p) {\n   \tll ans = 1;\n       a %= p;\n       while(b) {\n           if(b % 2 == 1) {\n               ans = (ans * a) % p;\n           a = (a * a) % p;\n           b /= 2;\n       }\n       return ans % p;\n   }\n   ```\n\n3. 其实还可以使用**位运算**，提升运行的速度，代码如下：\n\n   ```c++\n   typedef long long ll;\n   ll fast_power(ll a, ll b, ll p) {\n   \tll ans = 1;\n       a %= p;\n       while(b) {\n           if(b & 1) {\t\t// 如7二进制为0000 0111，1二进制为0000 0001，则7&1 = 0000 0001 = 1\n               ans = (ans * a) % p;\n           a = (a * a) % p;\n           b >>= 1;\t\t// 7二进制为0000 0111，向右位移一位为 0000 0011 = 3 （不足补0）\n       }\n       return ans % p;\n   }\n   ```\n\n   常见的位运算符有 与& 或| 右移>> 左移<< 异或^\n\n##### **最终代码：**\n\n```c++\n#include <iostream>\n\nusing namespace std;\n\ntypedef long long ll;\n\nll fast_power(ll a, ll b, ll p) {\n    a %= p;\n    ll ans = 1;\n    while(b) {\n        if(b & 1)\n            ans = (ans * a) % p;\n        a = (a * a) % p;\n        b >>= 1;\n    }\n    return ans % p;\n}\n\nint main() {\n    \n    ll a, b, p;\n    \n    cin >> a >> b >> p;\n    \n    cout << fast_power(a, b, p);\n    \n    return 0;\n}\n```\n\n\n\n> 参考资料：\n>\n> [1] [Pecco : 算法学习笔记(4)：快速幂](https://zhuanlan.zhihu.com/p/95902286)\n>\n> [2] [芸学习 : 【C++/算法】快速幂算法详解](https://www.bilibili.com/video/BV12r4y1w7tx?spm_id_from=333.337.search-card.all.click&vd_source=c155e4a52de51664d15aaf241c4a7656)\n","tags":["基本算法","快速幂","取模运算","位运算"],"categories":["基本算法"]},{"title":"最小生成树(Minimum Spanning Tree)","url":"/2022/02/23/minimum_spanning_tree/","content":"\n## 前言\n\n例题：[AizuOJ ALDS_12A](https://onlinejudge.u-aizu.ac.jp/courses/lesson/1/ALDS1/12/ALDS1_12_A)  &  [AizuOJ GRL_2_A](https://onlinejudge.u-aizu.ac.jp/courses/library/5/GRL/2/GRL_2_A )\n\n本题可以使用**普里姆(Prim)算法**或**克鲁斯卡尔(Kruskal)算法**进行实现。\n\n两种算法的简单比较：\n\n|         |      时间复杂度       | 最适合 |\n| :-----: | :-------------------: | :----: |\n|  Prim   |        O(n^2)         | 稠密图 |\n| Kruskal | O(E * log E)，E为边数 | 稀疏图 |\n\n视频：[最小生成树(Kruskal(克鲁斯卡尔)和Prim(普里姆))算法动画演示](https://www.bilibili.com/video/BV1Eb41177d1 \"WAY_zhong - BiliBili\")\n\n以下代码是 [AizuOJ GRL_2_A](https://onlinejudge.u-aizu.ac.jp/courses/library/5/GRL/2/GRL_2_A ) 的解法。\n\n## 普里姆算法\n\n代码如下：\n\n```c++\n#include <iostream>\n#include <cstdio>\n#include <vector>\n#include <limits.h>\n\nusing namespace std;\n\n#define MAX 10000\n\ntypedef pair<int, int> PII;\n\nvector<PII> D[MAX]; \t//PII(id, w)\nint sum = 0, d[MAX];\n//int p[MAX];\nbool seen[MAX] = {false};\n\nint main() {\n\tint V, E, s, t, w;\n\n\tscanf(\"%d %d\", &V, &E);\n\n\tfor (int i = 0; i < V; i++) {\n\t\td[i] = INT_MAX;\n\t}\n\n\tfor (int i = 0; i < E; i++) {\n\t\tscanf(\"%d %d %d\", &s, &t, &w);\n\t\tD[s].push_back(PII(t, w));\n\t\tD[t].push_back(PII(s, w));\n\t}\n\n\tint ct = 0;\n\ts = 0;\n\tseen[0] = true;\n\n\twhile (ct < V - 1) {\n\t\tfor (int i = 0; i < D[s].size(); i++) {\n\t\t\tt = D[s][i].first;\n\t\t\tw = D[s][i].second;\n\t\t\tif (!seen[t] && d[t] > w) {\n\t\t\t\td[t] = w;\n//\t\t\t\tp[t] = u;\n\t\t\t}\n\t\t}\n\n\t\tint min = 0;\n\t\tfor (int i = 0; i < V; i++)\n\t\t\tif (!seen[i] && d[i] < d[min])\n\t\t\t\tmin = i;\n\n\t\tseen[min] = true;\n\t\ts = min;\n\t\tsum += d[min];\n\t\tct++;\n\t}\n\n\tprintf(\"%d\\n\", sum);\n\n\treturn 0;\n}\n```\n\n运行结果：\n\n| Lang | Status | Judge |  Time  | Memory | Code |\n| :--: | :----: | :---: | :----: | :----: | :--: |\n| C++  |   AC   | 20/20 | 00.22s | 6024KB | 861B |\n\n## 克鲁斯卡尔算法\n\n代码如下：\n\n```c++\n#include <iostream>\n#include <cstdio>\n#include <vector>\n#include <algorithm>\n#include <limits.h>\n\nusing namespace std;\n\n#define MAX 10000\n\ntypedef struct {\n\tint v1, v2, w;\n} Info;\n\nvector<Info> D;\nint p[MAX], h[MAX], d[MAX];\n\nbool cmp(const Info a, const Info b) {\n\treturn a.w < b.w;\n}\n\nint find(int a) {\n\tif (p[a] != a) {\n\t\tp[a] = find(p[a]);\n\t}\n\treturn p[a];\n}\n\nvoid unite(int x, int y) {\n\tint rX = find(x);\n\tint rY = find(y);\n\n\tif (rX != rY) {\n\t\tif (h[rX] > h[rY])\n\t\t\tp[rY] = rX;\n\t\telse {\n\t\t\tp[rX] = rY;\n\t\t\tif (h[rX] == h[rY])\n\t\t\t\th[rY]++;\n\t\t}\n\t}\n}\n\n\nint main() {\n\tint V, E, sum = 0;\n\tint s, t, w;\n\n\tscanf(\"%d %d\", &V, &E);\n\n\tfor (int i = 0; i < V; i++) {\n\t\td[i] = INT_MAX;\n\t\tp[i] = i;\n\t\th[i] = 0;\n\t}\n\n\tfor (int i = 0; i < E; i++) {\n\t\tscanf(\"%d %d %d\", &s, &t, &w);\n\t\tInfo tmp = {s, t, w};\n\t\tD.push_back(tmp);\n\t}\n\n\tsort(D.begin(), D.end(), cmp);\n\n\tfor (int i = 0; i < E; i++) {\n\t\tif (find(D[i].v1) != find(D[i].v2)) {\n\t\t\tunite(D[i].v1, D[i].v2);\n\t\t\tsum += D[i].w;\n\t\t}\n\t}\n\n\tprintf(\"%d\\n\", sum);\n\n\treturn 0;\n}\n```\n\n运行结果：\n\n| Lang | Status | Judge |  Time  | Memory | Code  |\n| :--: | :----: | :---: | :----: | :----: | :---: |\n| C++  |   AC   | 20/20 | 00.02s | 4696KB | 1013B |\n\n  \n","tags":["图论","普里姆算法","克鲁斯卡尔算法","最小生成树"],"categories":["图论"]},{"title":"Hello World","url":"/2022/01/08/hello-world/","content":"emmm...\n"}]